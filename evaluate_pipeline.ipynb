{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üçì Strawberry & Peduncle: Segmentation, Matching & 3D Localization\n",
                "\n",
                "This notebook evaluates the full pipeline:\n",
                "1.  **Segmentation**: YOLOv11 detects Strawberries (Cubes) and Peduncles (Parallelepipeds).\n",
                "2.  **Association**: AffinityNet predicts which peduncle belongs to which strawberry.\n",
                "3.  **3D Localization**: Calculates XYZ coordinates in meters relative to the camera.\n",
                "\n",
                "## Models\n",
                "- **Segmentation**: `yolo11l-seg-strawberry-stem-2`\n",
                "- **Matching**: `affinity-net-strawberry-peduncle-maching-v1`\n",
                "\n",
                "## ‚ö†Ô∏è Troubleshooting\n",
                "If weights are not found, make sure you have added the correct Models to your Kaggle notebook usage."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# üì¶ Install Dependencies\n",
                "!pip install ultralytics opencv-python-headless matplotlib scikit-learn tqdm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import json\n",
                "import glob\n",
                "import numpy as np\n",
                "import cv2\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import matplotlib.pyplot as plt\n",
                "from ultralytics import YOLO\n",
                "from scipy.optimize import linear_sum_assignment\n",
                "from tqdm.notebook import tqdm\n",
                "\n",
                "# === CONFIGURATION ===\n",
                "# Dataset Path check\n",
                "POSSIBLE_DATASET_PATHS = [\n",
                "    \"/kaggle/input/strawberry-peduncle-segmentation/strawberry_peduncle_segmentation/dataset\",\n",
                "    \"/kaggle/input/strawberry-peduncle-segmentation/dataset\",\n",
                "    \"dataset\" # Local fallback\n",
                "]\n",
                "DATASET_PATH = None\n",
                "for p in POSSIBLE_DATASET_PATHS:\n",
                "    if os.path.exists(p):\n",
                "        DATASET_PATH = p\n",
                "        break\n",
                "\n",
                "if DATASET_PATH is None:\n",
                "    print(\"‚ö†Ô∏è DATASET NOT FOUND! Please check input paths.\")\n",
                "    DATASET_PATH = \"/kaggle/input/strawberry-peduncle-segmentation/strawberry_peduncle_segmentation/dataset\" # Default to try\n",
                "\n",
                "print(f\"üìÇ using Dataset Path: {DATASET_PATH}\")\n",
                "\n",
                "# Model Weights Check\n",
                "# Weights might be in slightly different folders depending on version\n",
                "WEIGHTS_YOLO = \"/kaggle/input/yolo11l-seg-strawberry-stem-2/pytorch/default/1/best.pt\"\n",
                "WEIGHTS_AFFINITY = \"/kaggle/input/affinity-net-strawberry-peduncle-maching-v1/pytorch/default/1/best_affinity_net.pth\"\n",
                "\n",
                "# Check if weights exist, simple search if not\n",
                "if not os.path.exists(WEIGHTS_YOLO):\n",
                "    found = glob.glob(\"/kaggle/input/yolo11l-seg-strawberry-stem-2/**/*.pt\", recursive=True)\n",
                "    if found:\n",
                "        WEIGHTS_YOLO = found[0]\n",
                "        print(f\"üîç Found YOLO weights at: {WEIGHTS_YOLO}\")\n",
                "    else:\n",
                "        print(f\"‚ùå YOLO Weights NOT FOUND at {WEIGHTS_YOLO}\")\n",
                "\n",
                "if not os.path.exists(WEIGHTS_AFFINITY):\n",
                "    found = glob.glob(\"/kaggle/input/affinity-net-strawberry-peduncle-maching-v1/**/*.pth\", recursive=True)\n",
                "    if found:\n",
                "        WEIGHTS_AFFINITY = found[0]\n",
                "        print(f\"üîç Found Affinity weights at: {WEIGHTS_AFFINITY}\")\n",
                "    else:\n",
                "        print(f\"‚ùå Affinity Weights NOT FOUND at {WEIGHTS_AFFINITY}\")\n",
                "\n",
                "# Camera Intrinsics (Unity Default)\n",
                "IMG_WIDTH = 1024\n",
                "IMG_HEIGHT = 1024\n",
                "FOV_VERTICAL_DEG = 60.0\n",
                "\n",
                "# Real object sizes (Meters)\n",
                "CUBE_RealHeight = 0.03  # 3 cm\n",
                "PARA_RealHeight = 0.02  # 2 cm (approx length for depth estimation)\n",
                "\n",
                "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "print(f\"‚úÖ Device: {DEVICE}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Define AffinityNet & Utils\n",
                "\n",
                "Defining the network architecture and feature extraction logic here to make the notebook self-contained."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class AffinityNet(nn.Module):\n",
                "    \"\"\"\n",
                "    MLP for predicting association affinity between parallelepiped and cube.\n",
                "    Uses only geometric/spatial features - no visual features needed.\n",
                "    \"\"\"\n",
                "    def __init__(self, spatial_dim=5, hidden_dims=[32, 16]):\n",
                "        super().__init__()\n",
                "        layers = []\n",
                "        prev_dim = spatial_dim\n",
                "        for hidden_dim in hidden_dims:\n",
                "            layers.extend([\n",
                "                nn.Linear(prev_dim, hidden_dim),\n",
                "                nn.ReLU(inplace=True),\n",
                "                nn.Dropout(0.3)\n",
                "            ])\n",
                "            prev_dim = hidden_dim\n",
                "        layers.extend([\n",
                "            nn.Linear(prev_dim, 1),\n",
                "            nn.Sigmoid()\n",
                "        ])\n",
                "        self.network = nn.Sequential(*layers)\n",
                "\n",
                "    def forward(self, spatial_features):\n",
                "        return self.network(spatial_features)\n",
                "\n",
                "    def predict_matrix(self, spatial_matrix):\n",
                "        N_para, N_cube, _ = spatial_matrix.shape\n",
                "        spatial_flat = spatial_matrix.reshape(-1, 5)\n",
                "        affinity_flat = self.forward(spatial_flat)\n",
                "        return affinity_flat.reshape(N_para, N_cube)\n",
                "\n",
                "def compute_spatial_features(para_bbox, cube_bbox, para_mask, cube_mask, image_size):\n",
                "    H, W = image_size\n",
                "    px1, py1, px2, py2 = para_bbox\n",
                "    cx1, cy1, cx2, cy2 = cube_bbox\n",
                "\n",
                "    # 1. Vertical distance info\n",
                "    vertical_dist = abs(py2 - cy1) / H\n",
                "    vertical_score = max(0, 1.0 - vertical_dist * 5.0)\n",
                "\n",
                "    # 2. Horizontal overlap\n",
                "    overlap_left = max(px1, cx1)\n",
                "    overlap_right = min(px2, cx2)\n",
                "    overlap_width = max(0, overlap_right - overlap_left)\n",
                "    para_width = px2 - px1\n",
                "    horizontal_overlap = overlap_width / (para_width + 1e-6)\n",
                "\n",
                "    # 3. Centeredness\n",
                "    para_center_x = (px1 + px2) / 2\n",
                "    cube_center_x = (cx1 + cx2) / 2\n",
                "    cube_width = cx2 - cx1\n",
                "    offset = abs(para_center_x - cube_center_x)\n",
                "    centeredness = max(0, 1.0 - offset / (cube_width / 2 + 1e-6))\n",
                "\n",
                "    # 4. Size ratio\n",
                "    para_area = (px2 - px1) * (py2 - py1)\n",
                "    cube_area = (cx2 - cx1) * (cy2 - cy1)\n",
                "    size_ratio = para_area / (cube_area + 1e-6)\n",
                "    size_ratio = min(size_ratio, 1.0)\n",
                "\n",
                "    # 5. Mask IoU\n",
                "    if para_mask is not None and cube_mask is not None:\n",
                "        intersection = np.logical_and(para_mask, cube_mask).sum()\n",
                "        union = np.logical_or(para_mask, cube_mask).sum()\n",
                "        mask_iou = intersection / (union + 1e-6)\n",
                "    else:\n",
                "        mask_iou = 0.0\n",
                "\n",
                "    return np.array([vertical_score, horizontal_overlap, centeredness, size_ratio, mask_iou], dtype=np.float32)\n",
                "\n",
                "def compute_spatial_features_batch(para_bboxes, cube_bboxes, para_masks, cube_masks, image_size):\n",
                "    N_para = len(para_bboxes)\n",
                "    N_cube = len(cube_bboxes)\n",
                "    spatial_matrix = np.zeros((N_para, N_cube, 5), dtype=np.float32)\n",
                "    for i in range(N_para):\n",
                "        for j in range(N_cube):\n",
                "            spatial_matrix[i, j] = compute_spatial_features(\n",
                "                para_bboxes[i], cube_bboxes[j],\n",
                "                para_masks[i] if para_masks is not None else None,\n",
                "                cube_masks[j] if cube_masks is not None else None,\n",
                "                image_size\n",
                "            )\n",
                "    return spatial_matrix"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. 3D Coordinate Calculation\n",
                "\n",
                "We calculate the 3D position $(X, Y, Z)$ of each object using the Pinhole Camera Model.\n",
                "\n",
                "### Intrinsics\n",
                "Given $FOV_{vert} = 60^{\\circ}$ and Image Height $H = 1024$:\n",
                "\n",
                "$f_y = \\frac{H / 2}{\\tan(FOV / 2)}$\n",
                "\n",
                "### Depth Estimation ($Z$)\n",
                "We use the known physical height of the object and its projected pixel height:\n",
                "\n",
                "$Z = \\frac{f_y \\cdot H_{real}}{H_{pixel}}$\n",
                "\n",
                "### X, Y Estimation\n",
                "$X = \\frac{(u - c_x) \\cdot Z}{f_x}$\n",
                "$Y = -\\frac{(v - c_y) \\cdot Z}{f_y}$ (Unity Y is up, Image Y is down)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_intrinsics(img_width, img_height, fov_deg):\n",
                "    fov_rad = np.deg2rad(fov_deg)\n",
                "    f_y = (img_height / 2) / np.tan(fov_rad / 2)\n",
                "    f_x = f_y  # Square pixels\n",
                "    cx = img_width / 2\n",
                "    cy = img_height / 2\n",
                "    return f_x, f_y, cx, cy\n",
                "\n",
                "def pixel_to_3d(bbox, real_height, intrinsics):\n",
                "    \"\"\"\n",
                "    Convert bounding box to 3D centroid.\n",
                "    bbox: [x1, y1, x2, y2]\n",
                "    real_height: physical height in meters\n",
                "    intrinsics: (fx, fy, cx, cy)\n",
                "    \"\"\"\n",
                "    fx, fy, cx, cy = intrinsics\n",
                "    x1, y1, x2, y2 = bbox\n",
                "    \n",
                "    # Pixel dimensions\n",
                "    h_pixel = max(y2 - y1, 1e-5)\n",
                "    w_pixel = max(x2 - x1, 1e-5)\n",
                "    \n",
                "    # Centroid in pixels\n",
                "    u_center = (x1 + x2) / 2\n",
                "    v_center = (y1 + y2) / 2\n",
                "    \n",
                "    # Estimate Depth Z\n",
                "    # Z = (f * real_H) / pixel_H\n",
                "    Z = (fy * real_height) / h_pixel\n",
                "    \n",
                "    # Back-project to X, Y\n",
                "    # Unity Coordinate System: Y is Up, we might need to adjust signs depending on needs.\n",
                "    # Here: Standard CV pinhole: X right, Y down, Z forward.\n",
                "    # Unity: X right, Y up, Z forward.\n",
                "    \n",
                "    X = (u_center - cx) * Z / fx\n",
                "    Y = -(v_center - cy) * Z / fy  # Invert Y to match Unity's 'Up' direction approx\n",
                "    \n",
                "    return float(X), float(Y), float(Z)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Pipeline\n",
                "\n",
                "1.  **Detect Objects** (YOLO)\n",
                "2.  **Separate Classes**\n",
                "3.  **Compute Affinity**\n",
                "4.  **Match**\n",
                "5.  **Compute 3D**\n",
                "6.  **Visualize**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load Models\n",
                "print(\"üöÄ Loading Models...\")\n",
                "\n",
                "# 1. YOLO\n",
                "try:\n",
                "    if os.path.exists(WEIGHTS_YOLO):\n",
                "        yolo_model = YOLO(WEIGHTS_YOLO)\n",
                "        print(\"‚úÖ YOLO Loaded\")\n",
                "    else:\n",
                "        print(f\"‚ùå ERROR: YOLO Weights not found anywhere! Check inputs.\")\n",
                "        # Dummy model to prevent execution crash if just checking paths\n",
                "        yolo_model = None \n",
                "except Exception as e:\n",
                "    print(f\"‚ö†Ô∏è Error loading YOLO: {e}\")\n",
                "    yolo_model = None\n",
                "\n",
                "# 2. AffinityNet\n",
                "affinity_model = AffinityNet().to(DEVICE)\n",
                "if os.path.exists(WEIGHTS_AFFINITY):\n",
                "    affinity_model.load_state_dict(torch.load(WEIGHTS_AFFINITY, map_location=DEVICE))\n",
                "    affinity_model.eval()\n",
                "    print(\"‚úÖ AffinityNet Loaded\")\n",
                "else:\n",
                "    print(f\"‚ùå ERROR: AffinityNet Weights not found at {WEIGHTS_AFFINITY}\")\n",
                "    \n",
                "# Intrinsics\n",
                "fx, fy, cx, cy = get_intrinsics(IMG_WIDTH, IMG_HEIGHT, FOV_VERTICAL_DEG)\n",
                "intrinsics = (fx, fy, cx, cy)\n",
                "print(f\"üì∏ Intrinsics: fx={fx:.1f}, fy={fy:.1f}, cx={cx:.1f}, cy={cy:.1f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def process_image(image_path, visualize=False):\n",
                "    if yolo_model is None:\n",
                "        print(\"‚ùå YOLO model not loaded, skipping inference.\")\n",
                "        return None\n",
                "        \n",
                "    filename = os.path.basename(image_path)\n",
                "    \n",
                "    # 1. Inference\n",
                "    results = yolo_model(image_path, conf=0.5, verbose=False)[0]\n",
                "    \n",
                "    # 2. Extract Data\n",
                "    boxes = results.boxes.xyxy.cpu().numpy()\n",
                "    classes = results.boxes.cls.cpu().numpy()\n",
                "    if results.masks is not None:\n",
                "        masks = results.masks.data.cpu().numpy()  # [N, H, W]\n",
                "    else:\n",
                "        masks = None\n",
                "        \n",
                "    # Separate by class (0: cube/strawberry, 1: para/peduncle)\n",
                "    # Note: Check dataset.yaml for exact class IDs. Assuming 0=Cube, 1=Para based on standard order\n",
                "    # BUT: COCO annotations had 1=Cube, 2=Para. YOLO classes are 0-indexed.\n",
                "    # So YOLO 0 -> Cube, YOLO 1 -> Para\n",
                "    \n",
                "    cube_indices = np.where(classes == 0)[0]\n",
                "    para_indices = np.where(classes == 1)[0]\n",
                "    \n",
                "    cubes = []\n",
                "    parallelepipeds = []\n",
                "    \n",
                "    # Process Cubes\n",
                "    for idx in cube_indices:\n",
                "        box = boxes[idx]\n",
                "        mask = masks[idx] if masks is not None else None\n",
                "        x, y, z = pixel_to_3d(box, CUBE_RealHeight, intrinsics)\n",
                "        cubes.append({\n",
                "            'id': int(idx),\n",
                "            'bbox': box.tolist(),\n",
                "            'mask': mask,\n",
                "            'pos_3d': [x, y, z],\n",
                "            'class': 'strawberry'\n",
                "        })\n",
                "        \n",
                "    # Process Paras\n",
                "    for idx in para_indices:\n",
                "        box = boxes[idx]\n",
                "        mask = masks[idx] if masks is not None else None\n",
                "        x, y, z = pixel_to_3d(box, PARA_RealHeight, intrinsics)\n",
                "        parallelepipeds.append({\n",
                "            'id': int(idx),\n",
                "            'bbox': box.tolist(),\n",
                "            'mask': mask,\n",
                "            'pos_3d': [x, y, z],\n",
                "            'class': 'peduncle',\n",
                "            'matched_cube_id': None\n",
                "        })\n",
                "        \n",
                "    # 3. Association\n",
                "    if len(cubes) > 0 and len(parallelepipeds) > 0:\n",
                "        cube_boxes = np.array([c['bbox'] for c in cubes])\n",
                "        para_boxes = np.array([p['bbox'] for p in parallelepipeds])\n",
                "        cube_masks_arr = np.array([c['mask'] for c in cubes]) if masks is not None else None\n",
                "        para_masks_arr = np.array([p['mask'] for p in parallelepipeds]) if masks is not None else None\n",
                "        \n",
                "        # Compute features\n",
                "        spatial_matrix = compute_spatial_features_batch(\n",
                "            para_boxes, cube_boxes,\n",
                "            para_masks_arr, cube_masks_arr,\n",
                "            (IMG_HEIGHT, IMG_WIDTH)\n",
                "        )\n",
                "        \n",
                "        # Predict affinity\n",
                "        spatial_tensor = torch.from_numpy(spatial_matrix).to(DEVICE)\n",
                "        with torch.no_grad():\n",
                "            affinity_matrix = affinity_model.predict_matrix(spatial_tensor).cpu().numpy()\n",
                "            \n",
                "        # Match (Hungarian)\n",
                "        row_ind, col_ind = linear_sum_assignment(-affinity_matrix)\n",
                "        \n",
                "        for r, c in zip(row_ind, col_ind):\n",
                "            score = affinity_matrix[r, c]\n",
                "            if score > 0.5:\n",
                "                parallelepipeds[r]['matched_cube_id'] = cubes[c]['id']\n",
                "\n",
                "    # 4. Visualization\n",
                "    if visualize:\n",
                "        img = cv2.imread(image_path)\n",
                "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
                "        \n",
                "        plt.figure(figsize=(12, 12))\n",
                "        plt.imshow(img)\n",
                "        ax = plt.gca()\n",
                "        \n",
                "        # Draw Cubes\n",
                "        for c in cubes:\n",
                "            x1, y1, x2, y2 = c['bbox']\n",
                "            rect = plt.Rectangle((x1, y1), x2-x1, y2-y1, fill=False, edgecolor='red', linewidth=2)\n",
                "            ax.add_patch(rect)\n",
                "            ax.text(x1, y1-5, f\"Straw {c['id']} {c['pos_3d'][2]:.2f}m\", color='red', fontsize=10, backgroundcolor='white')\n",
                "            \n",
                "        # Draw Paras & Lines\n",
                "        for p in parallelepipeds:\n",
                "            x1, y1, x2, y2 = p['bbox']\n",
                "            rect = plt.Rectangle((x1, y1), x2-x1, y2-y1, fill=False, edgecolor='green', linewidth=2)\n",
                "            ax.add_patch(rect)\n",
                "            ax.text(x1, y1-5, f\"Stem {p['id']}\", color='green', fontsize=8, backgroundcolor='white')\n",
                "            \n",
                "            if p['matched_cube_id'] is not None:\n",
                "                cube = next((c for c in cubes if c['id'] == p['matched_cube_id']), None)\n",
                "                if cube:\n",
                "                    c_x = (cube['bbox'][0] + cube['bbox'][2]) / 2\n",
                "                    c_y = (cube['bbox'][1] + cube['bbox'][3]) / 2\n",
                "                    p_x = (x1 + x2) / 2\n",
                "                    p_y = (y1 + y2) / 2\n",
                "                    plt.plot([c_x, p_x], [c_y, p_y], color='yellow', linewidth=2)\n",
                "        \n",
                "        plt.axis('off')\n",
                "        plt.title(f\"Results: {filename}\\nYellow lines = Predicted Associations\")\n",
                "        plt.show()\n",
                "        \n",
                "    # 5. Output Data Format\n",
                "    output_data = {\n",
                "        'image': filename,\n",
                "        'strawberries': [\n",
                "            {k: v for k, v in c.items() if k != 'mask' and k != 'bbox'} for c in cubes\n",
                "        ],\n",
                "        'peduncles': [\n",
                "            {k: v for k, v in p.items() if k != 'mask' and k != 'bbox'} for p in parallelepipeds\n",
                "        ]\n",
                "    }\n",
                "    # Add back bbox for JSON (converted to simple list)\n",
                "    for s in output_data['strawberries']:\n",
                "        cube_ref = next(c for c in cubes if c['id'] == s['id'])\n",
                "        s['bbox'] = cube_ref['bbox']\n",
                "\n",
                "    for p in output_data['peduncles']:\n",
                "        para_ref = next(par for par in parallelepipeds if par['id'] == p['id'])\n",
                "        p['bbox'] = para_ref['bbox']\n",
                "\n",
                "    return output_data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === RUN ON TEST IMAGES ===\n",
                "if DATASET_PATH is not None:\n",
                "    # Try multiple subfolder structures\n",
                "    search_paths = [\n",
                "        os.path.join(DATASET_PATH, \"images\", \"*.png\"),\n",
                "        os.path.join(DATASET_PATH, \"*.png\")\n",
                "    ]\n",
                "    test_images = []\n",
                "    for sp in search_paths:\n",
                "        found = glob.glob(sp)\n",
                "        if len(found) > 0:\n",
                "            test_images = found\n",
                "            break\n",
                "    \n",
                "    test_images = test_images[:5]\n",
                "else:\n",
                "    test_images = []\n",
                "\n",
                "results_json = []\n",
                "\n",
                "print(f\"üß™ Testing on {len(test_images)} images...\")\n",
                "\n",
                "if len(test_images) == 0:\n",
                "    print(\"‚ö†Ô∏è NO IMAGES FOUND. Check if the dataset is added to the notebook input correctly.\")\n",
                "\n",
                "for img_path in test_images:\n",
                "    try:\n",
                "        res = process_image(img_path, visualize=True)\n",
                "        if res is not None:\n",
                "            results_json.append(res)\n",
                "    except Exception as e:\n",
                "        print(f\"‚ö†Ô∏è Error processing {img_path}: {e}\")\n",
                "\n",
                "# Save JSON\n",
                "with open(\"detailed_results.json\", \"w\") as f:\n",
                "    json.dump(results_json, f, indent=2)\n",
                "    \n",
                "print(\"\\n‚úÖ Saved detailed_results.json\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === JSON PREVIEW ===\n",
                "if len(results_json) > 0:\n",
                "    print(json.dumps(results_json[0], indent=2))\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è No results to preview. Check logs for errors.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Visualizing 3D Positions\n",
                "Here we do a simple scatter plot of the detected objects in 3D (X-Z plane, Top-down view)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_3d_topdown(results):\n",
                "    plt.figure(figsize=(10, 10))\n",
                "    \n",
                "    for entry in results:\n",
                "        for s in entry['strawberries']:\n",
                "            x, y, z = s['pos_3d']\n",
                "            plt.scatter(x, z, c='red', marker='s', s=100, label='Strawberry' if 'Strawberry' not in plt.gca().get_legend_handles_labels()[1] else \"\")\n",
                "            \n",
                "        for p in entry['peduncles']:\n",
                "            x, y, z = p['pos_3d']\n",
                "            plt.scatter(x, z, c='green', marker='^', s=50, label='Peduncle' if 'Peduncle' not in plt.gca().get_legend_handles_labels()[1] else \"\")\n",
                "            \n",
                "            # Draw connection\n",
                "            if p['matched_cube_id'] is not None:\n",
                "                match = next((s for s in entry['strawberries'] if s['id'] == p['matched_cube_id']), None)\n",
                "                if match:\n",
                "                    mx, my, mz = match['pos_3d']\n",
                "                    plt.plot([x, mx], [z, mz], 'k--', alpha=0.3)\n",
                "\n",
                "    plt.xlabel(\"X (meters)\")\n",
                "    plt.ylabel(\"Z (Depth, meters)\")\n",
                "    plt.title(\"Top-Down View of Detected Objects (X-Z Plane)\")\n",
                "    plt.grid(True)\n",
                "    plt.legend()\n",
                "    plt.axis('equal')\n",
                "    plt.show()\n",
                "\n",
                "if len(results_json) > 0:\n",
                "    plot_3d_topdown(results_json)\n",
                "else:\n",
                "    print(\"‚ö†Ô∏è No data to plot.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}