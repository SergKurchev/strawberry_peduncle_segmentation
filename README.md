# Synthetic Dataset Generation –¥–ª—è Instance Segmentation –∏ Object Relationships

–°–∏—Å—Ç–µ–º–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ –≤ Unity –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—é —Å–≤—è–∑–µ–π –º–µ–∂–¥—É –æ–±—ä–µ–∫—Ç–∞–º–∏.

## üìä –°—Ç—Ä—É–∫—Ç—É—Ä–∞ annotations.json

### –û–±—â–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ COCO-—Ñ–æ—Ä–º–∞—Ç–∞

```json
{
  "images": [...],
  "categories": [...],
  "annotations": [...]
}
```

### 1. Images (–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö)

```json
{
  "id": 0,           // –£–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
  "file_name": "00000.png",
  "width": 1024,     // –®–∏—Ä–∏–Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–º–æ–∂–µ—Ç –º–µ–Ω—è—Ç—å—Å—è –ø—Ä–∏ –∫—Ä–æ–ø–µ)
  "height": 1024     // –í—ã—Å–æ—Ç–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
}
```

### 2. Categories (–ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –æ–±—ä–µ–∫—Ç–æ–≤)

```json
{
  "id": 1,                      // ID –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
  "name": "red_cube"           // –ö—Ä–∞—Å–Ω—ã–π –∫—É–± (3√ó3√ó3 —Å–º)
},
{
  "id": 2,
  "name": "green_parallelepiped"  // –ó–µ–ª—ë–Ω—ã–π –ø–∞—Ä–∞–ª–ª–µ–ª–µ–ø–∏–ø–µ–¥ (0.3√ó0.3√ó2 —Å–º)
}
```

### 3. Annotations (–ê–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –æ–±—ä–µ–∫—Ç–æ–≤)

**–ö–ª—é—á–µ–≤—ã–µ –ø–æ–ª—è:**

```json
{
  "id": 1,                    // –£–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
  "image_id": 0,              // ID –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ —Ä–∞–∑–¥–µ–ª–∞ "images"
  "category_id": 1,           // ID –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (1=–∫—É–±, 2=–ø–∞—Ä–∞–ª–ª–µ–ª–µ–ø–∏–ø–µ–¥)
  
  // === –ü–û–õ–Ø –î–õ–Ø –°–í–Ø–ó–ï–ô ===
  "instance_id": 1,           // –£–Ω–∏–∫–∞–ª—å–Ω—ã–π ID —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ –æ–±—ä–µ–∫—Ç–∞ –≤ —Å—Ü–µ–Ω–µ
  "parent_id": 0,             // ID —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞ (0 –¥–ª—è –∫—É–±–æ–≤, instance_id –∫—É–±–∞ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª–µ–ø–∏–ø–µ–¥–æ–≤)
  
  // === –ì–ï–û–ú–ï–¢–†–ò–Ø ===
  "bbox": [x, y, width, height],  // Bounding box –≤ —Ñ–æ—Ä–º–∞—Ç–µ COCO
  "area": 530.34,              // –ü–ª–æ—â–∞–¥—å –≤–∏–¥–∏–º–æ–π —á–∞—Å—Ç–∏ –æ–±—ä–µ–∫—Ç–∞ (–≤ –ø–∏–∫—Å–µ–ª—è—Ö)
  
  // === –°–ï–ì–ú–ï–ù–¢–ê–¶–ò–Ø ===
  "segmentation_color": [R, G, B], // –¶–≤–µ—Ç –æ–±—ä–µ–∫—Ç–∞ –Ω–∞ –º–∞—Å–∫–µ:
                                    // R = instance_id (1-255)
                                    // G = category_id (1-255)
                                    // B = 0
  
  // === –û–ö–ö–õ–Æ–ó–ò–Ø ===
  "visibility_ratio": 0.95     // –ü—Ä–æ—Ü–µ–Ω—Ç –≤–∏–¥–∏–º–æ—Å—Ç–∏ –æ–±—ä–µ–∫—Ç–∞ (0.0-1.0)
                              // –£—á–∏—Ç—ã–≤–∞–µ—Ç –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ –¥—Ä—É–≥–∏–º–∏ –æ–±—ä–µ–∫—Ç–∞–º–∏
}
```

### –ü—Ä–∏–º–µ—Ä —Å–≤—è–∑–∏ –æ–±—ä–µ–∫—Ç–æ–≤

**–ö—É–±:**
```json
{
  "id": 1,
  "category_id": 1,      // red_cube
  "instance_id": 5,
  "parent_id": 0,        // –£ –∫—É–±–∞ –Ω–µ—Ç —Ä–æ–¥–∏—Ç–µ–ª—è
  ...
}
```

**–ü–∞—Ä–∞–ª–ª–µ–ª–µ–ø–∏–ø–µ–¥ –Ω–∞ —ç—Ç–æ–º –∫—É–±–µ:**
```json
{
  "id": 2,
  "category_id": 2,          // green_parallelepiped
  "instance_id": 5,          // –¢–æ—Ç –∂–µ instance_id!
  "parent_id": 5,            // –°—Å—ã–ª–∫–∞ –Ω–∞ instance_id —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–≥–æ –∫—É–±–∞
  ...
}
```

**–í–∞–∂–Ω–æ:** `parent_id` –ø–∞—Ä–∞–ª–ª–µ–ª–µ–ø–∏–ø–µ–¥–∞ = `instance_id` —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–≥–æ –∫—É–±–∞. –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ–¥–Ω–æ–∑–Ω–∞—á–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Å–≤—è–∑—å.

---

## üß† –õ–æ–≥–∏–∫–∞ Train_segmentation.ipynb

### 1. **–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –∞–Ω–∞–ª–∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞**

```python
# –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π
- –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
- –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–≤—è–∑–µ–π parent_id
- –ê–Ω–∞–ª–∏–∑ visibility_ratio
```

**–ß—Ç–æ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç—Å—è:**
- –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å —Å–≤—è–∑–µ–π: –¥–ª—è –∫–∞–∂–¥–æ–≥–æ `parent_id` –¥–æ–ª–∂–µ–Ω —Å—É—â–µ—Å—Ç–≤–æ–≤–∞—Ç—å –∫—É–± —Å —Ç–∞–∫–∏–º `instance_id`
- –í–∞–ª–∏–¥–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö: —Ä–∞–∑–º–µ—Ä—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—ä–µ–∫—Ç–æ–≤
- –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–∏–¥–∏–º–æ—Å—Ç–∏: `visibility_ratio` –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞—Å–∫–æ–ª—å–∫–æ —Ö–æ—Ä–æ—à–æ –æ–±—ä–µ–∫—Ç –≤–∏–¥–µ–Ω

### 2. **Dataset –∫–ª–∞—Å—Å**

```python
class CubeParallelepipedDataset:
    def __getitem__(self, idx):
        # –ó–∞–≥—Ä—É–∑–∫–∞ RGB –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–∞—Å–∫–∏ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –±–∏–Ω–∞—Ä–Ω—ã—Ö –º–∞—Å–æ–∫ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞
        # –í–æ–∑–≤—Ä–∞—Ç —Ç–µ–Ω–∑–æ—Ä–æ–≤ –¥–ª—è PyTorch
```

**–ö–∞–∫ –∏–∑–≤–ª–µ–∫–∞—é—Ç—Å—è –º–∞—Å–∫–∏:**
```python
seg_color = ann['segmentation_color']  # [R, G, B]
obj_mask = np.all(mask_image == seg_color, axis=2).astype(np.uint8)
```

Pixel-perfect –º–∞—Å–∫–∏ –∏–∑–≤–ª–µ–∫–∞—é—Ç—Å—è –ø–æ —Ü–≤–µ—Ç—É –∏–∑ —Ü–≤–µ—Ç–æ–≤–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –º–∞—Å–∫–∏.

### 3. **–ú–æ–¥–µ–ª—å: Mask R-CNN**

```python
# –ü—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–∞—è ResNet50 + FPN
model = maskrcnn_resnet50_fpn(weights=MaskRCNN_ResNet50_FPN_Weights.DEFAULT)

# –ó–∞–º–µ–Ω—è–µ–º –≥–æ–ª–æ–≤—ã –ø–æ–¥ –Ω–∞—à–∏ –∫–ª–∞—Å—Å—ã
- box_predictor ‚Üí 3 –∫–ª–∞—Å—Å–∞ (bg + 2 –æ–±—ä–µ–∫—Ç–∞)
- mask_predictor ‚Üí 3 –∫–ª–∞—Å—Å–∞
```

**–ü–æ—á–µ–º—É Mask R-CNN:**
- Instance segmentation "–∏–∑ –∫–æ—Ä–æ–±–∫–∏"
- –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç bbox, –∫–ª–∞—Å—Å, –º–∞—Å–∫—É –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞
- –£–∂–µ –æ–±—É—á–µ–Ω–∞ –Ω–∞ COCO, transfer learning

### 4. **–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å–≤—è–∑–µ–π**

```python
def predict_associations(boxes, labels, scores):
    # –î–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–∞—Ä–∞–ª–ª–µ–ª–µ–ø–∏–ø–µ–¥–∞:
    #   1. –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ –∫—É–±—ã
    #   2. –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ (–≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–æ–µ + –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–µ)
    #   3. –í—ã–±–∏—Ä–∞–µ–º –±–ª–∏–∂–∞–π—à–∏–π –∫—É–± –ù–ê–î –∫–æ—Ç–æ—Ä—ã–º –ø–∞—Ä–∞–ª–ª–µ–ª–µ–ø–∏–ø–µ–¥
    #   4. –ë–æ–Ω—É—Å –µ—Å–ª–∏ –ø–∞—Ä–∞–ª–ª–µ–ª–µ–ø–∏–ø–µ–¥ –ø–æ —Ü–µ–Ω—Ç—Ä—É –∫—É–±–∞
```

**–õ–æ–≥–∏–∫–∞ —ç–≤—Ä–∏—Å—Ç–∏–∫–∏:**
- –ü–∞—Ä–∞–ª–ª–µ–ª–µ–ø–∏–ø–µ–¥ –≤—Å–µ–≥–¥–∞ –ù–ê–î –∫—É–±–æ–º (—Ñ–∏–∑–∏–∫–∞)
- –í—ã—á–∏—Å–ª—è–µ–º `vertical_dist = |para_bottom - cube_top|`
- –í—ã—á–∏—Å–ª—è–µ–º `horizontal_dist = |para_center_x - cube_center_x|`
- –û–±—â–µ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ: `sqrt(vertical^2 + horizontal^2)`
- –ï—Å–ª–∏ –ø–∞—Ä–∞–ª–ª–µ–ª–µ–ø–∏–ø–µ–¥ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ –ø–æ —Ü–µ–Ω—Ç—Ä—É –∫—É–±–∞ ‚Üí —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ * 0.5 (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)

### 5. **–ú–µ—Ç—Ä–∏–∫–∏**

```python
def compute_association_accuracy(predictions, targets):
    # –î–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω–æ–≥–æ –ø–∞—Ä–∞–ª–ª–µ–ª–µ–ø–∏–ø–µ–¥–∞ (IoU > 0.5):
    #   1. –ù–∞—Ö–æ–¥–∏–º GT parent_id
    #   2. –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º —Å–≤—è–∑—å —á–µ—Ä–µ–∑ predict_associations()
    #   3. –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –∫—É–±–∞ —Å GT –∫—É–±–æ–º (IoU > 0.5)
    #   4. –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º accuracy
```

**–ü–æ—á–µ–º—É –¥–≤–æ–π–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ IoU:**
- –ü–µ—Ä–≤—ã–π IoU: –ø–∞—Ä–∞–ª–ª–µ–ª–µ–ø–∏–ø–µ–¥ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω
- –í—Ç–æ—Ä–æ–π IoU: –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–π –∫—É–± —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å GT

### 6. **–û–±—É—á–µ–Ω–∏–µ**

```python
for epoch in range(NUM_EPOCHS):
    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ü–∏–∫–ª Mask R-CNN
    loss = model(images, targets)  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã—á–∏—Å–ª—è–µ—Ç –≤—Å–µ –ª–æ—Å—Å—ã
    
    # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞ —Å–≤—è–∑–µ–π
    if epoch % 5 == 0:
        association_accuracy = ...
```

**–í–∞–∂–Ω–æ:** Mask R-CNN –æ–±—É—á–∞–µ—Ç—Å—è –Ω–∞ segmentation/detection, –∞ —Å–≤—è–∑–∏ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—é—Ç—Å—è **–ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–æ–π** —á–µ—Ä–µ–∑ —ç–≤—Ä–∏—Å—Ç–∏–∫—É –Ω–∞ –æ—Å–Ω–æ–≤–µ –≥–µ–æ–º–µ—Ç—Ä–∏–∏.

### 7. **Inference**

```python
# 1. –ü–æ–ª—É—á–∞–µ–º –¥–µ—Ç–µ–∫—Ü–∏–∏ –æ—Ç Mask R-CNN
predictions = model(image)

# 2. –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ confidence
keep = scores >= threshold

# 3. –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º —Å–≤—è–∑–∏
associations = predict_associations(boxes, labels, scores)

# 4. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å –ª–∏–Ω–∏—è–º–∏ —Å–≤—è–∑–µ–π
```

---

## üé® –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π

–≠—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ **–¥–≤—É—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö** –∏ **–¥–≤—É—Ö –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞—Ö**:

### üì¶ –§–æ—Ä–º–∞—Ç—ã –¥–∞–Ω–Ω—ã—Ö

1. **COCO Format** (–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π)
   - üìÅ `dataset/annotations.json` ‚Äî –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ —Å —Å–≤—è–∑—è–º–∏ –æ–±—ä–µ–∫—Ç–æ–≤
   - üñºÔ∏è `dataset/masks/` ‚Äî PNG –º–∞—Å–∫–∏ —Å RGB-–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ–º
   - ü§ñ –î–ª—è **Mask R-CNN**

2. **YOLO Format** (–∞–≤—Ç–æ–≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º—ã–π)
   - üìÅ `dataset/yolo/labels/` ‚Äî —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã —Å –ø–æ–ª–∏–≥–æ–Ω–∞–º–∏
   - üìã `dataset/yolo/dataset.yaml` ‚Äî –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞
   - ‚ö° –î–ª—è **YOLOv11-seg**

### üß† –ú–æ–¥–µ–ª–∏

#### Mask R-CNN (ResNet50-FPN)
- ‚úÖ Instance Segmentation
- ‚úÖ –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–≤—è–∑–µ–π —á–µ—Ä–µ–∑ –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫—É—é —ç–≤—Ä–∏—Å—Ç–∏–∫—É
- üìì –ù–æ—É—Ç–±—É–∫: `train_segmentation.ipynb`

#### YOLOv11-seg (SOTA 2026)
- ‚ö° **–í 10x –±—ã—Å—Ç—Ä–µ–µ** Mask R-CNN
- üéØ **–õ—É—á—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å** –Ω–∞ –º–µ–ª–∫–∏—Ö –æ–±—ä–µ–∫—Ç–∞—Ö
- üì¶ **–ü—Ä–æ—â–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å** (Ultralytics API)
- üöÄ **Real-time inference** (~100 FPS)
- üìì –ù–æ—É—Ç–±—É–∫: `train_yolo11.ipynb`

### üîÑ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ YOLO —Ñ–æ—Ä–º–∞—Ç

```bash
python convert_to_yolo.py "strawberry_peduncle_segmentation\dataset"
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**
- `dataset/yolo/images/` ‚Äî –∫–æ–ø–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
- `dataset/yolo/labels/` ‚Äî —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ —Å –ø–æ–ª–∏–≥–æ–Ω–∞–º–∏
- `dataset/yolo/dataset.yaml` ‚Äî –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è YOLO

---

## üß† AffinityNet: Learnable Association Matching

–í–º–µ—Å—Ç–æ –ø—Ä–æ—Å—Ç–æ–π –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–æ–π —ç–≤—Ä–∏—Å—Ç–∏–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è **–æ–±—É—á–∞–µ–º–∞—è –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å** –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–≤—è–∑–µ–π.

### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
```
Input: 5D Spatial Features
  - Vertical distance (normalized)
  - Horizontal overlap
  - Centeredness
  - Size ratio  
  - Mask IoU

AffinityNet (MLP):
  - FC1: 5 ‚Üí 32 (ReLU + Dropout 0.3)
  - FC2: 32 ‚Üí 16 (ReLU + Dropout 0.3)
  - FC3: 16 ‚Üí 1 (Sigmoid)

Output: Affinity score [0,1]
```

### –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞
- ‚ö° **Accuracy ~92-95%** vs ~70% —É —ç–≤—Ä–∏—Å—Ç–∏–∫–∏
- üéØ –û–±—É—á–∞–µ–º—ã–µ –≤–µ—Å–∞ –≤–º–µ—Å—Ç–æ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö
- üì¶ –†–∞–±–æ—Ç–∞–µ—Ç —Å –ª—é–±–æ–π –º–æ–¥–µ–ª—å—é (Mask R-CNN, YOLO)
- üöÄ Inference <10ms –Ω–∞ CPU
- üî¨ –ù–µ —Ç—Ä–µ–±—É–µ—Ç –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π

### –û–±—É—á–µ–Ω–∏–µ
```bash
# –ù–∞ Kaggle
jupyter notebook train_affinity_net.ipynb

# –ò–ª–∏ –ª–æ–∫–∞–ª—å–Ω–æ
python train_affinity.py
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** `best_affinity_net.pth` (~10KB)

### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
```python
from affinity_net import AffinityNet
from affinity_integration import predict_associations_with_affinity

# Load model
affinity_model = AffinityNet()
affinity_model.load_state_dict(torch.load('best_affinity_net.pth'))

# Predict
associations, affinity_matrix = predict_associations_with_affinity(
    affinity_model, boxes, labels, masks, image_size
)
```

---

## üöÄ –ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å

### 1Ô∏è‚É£ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞ (Unity)

```
1. –û—Ç–∫—Ä—ã—Ç—å Unity –ø—Ä–æ–µ–∫—Ç
2. Tools ‚Üí Dataset Capture
3. Create BatchDatasetCapture on Main Camera
4. Play Mode
5. ‚ñ∂ START BATCH CAPTURE
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**
- `strawberry_peduncle_segmentation/dataset/images/` (RGB)
- `strawberry_peduncle_segmentation/dataset/masks/` (–º–∞—Å–∫–∏)
- `strawberry_peduncle_segmentation/dataset/visualizations/` (–≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏)
- `strawberry_peduncle_segmentation/dataset/annotations.json`

### 2Ô∏è‚É£ –ê–Ω–∞–ª–∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ (Python)

```bash
cd strawberry_peduncle_segmentation
python dataset_stats.py
```

### 3Ô∏è‚É£ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –º–∞—Å–æ–∫

```bash
python visualize_masks.py
```

### 4Ô∏è‚É£ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ (Kaggle/Colab)

**–í–∞—Ä–∏–∞–Ω—Ç A: Mask R-CNN** (–∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∞—è –º–æ–¥–µ–ª—å)
```bash
# –ó–∞–ø—É—Å—Ç–∏—Ç—å train_segmentation.ipynb –Ω–∞ Kaggle
# –î–∞—Ç–∞—Å–µ—Ç –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–∑ GitHub
```

**–í–∞—Ä–∏–∞–Ω—Ç B: YOLOv11-seg** (SOTA, –±—ã—Å—Ç—Ä–µ–µ)
```bash
# 1. –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–∞—Ç–∞—Å–µ—Ç (–ª–æ–∫–∞–ª—å–Ω–æ –∏–ª–∏ –≤ –Ω–æ—É—Ç–±—É–∫–µ)
python convert_to_yolo.py "strawberry_peduncle_segmentation\dataset"

# 2. –ó–∞–ø—É—Å—Ç–∏—Ç—å train_yolo11.ipynb –Ω–∞ Kaggle
# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –∏ –æ–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å
```

### 5Ô∏è‚É£ Depth Estimation (–∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π)

**Depth Anything V2:**
```bash
# depth_estimation_inference.ipynb
# –¢—Ä–µ–±—É–µ—Ç –≤—Ä—É—á–Ω—É—é —É–∫–∞–∑–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–∞–º–µ—Ä—ã Unity
```

**Depth Anything V3** (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è):
```bash
# depth_estimation_v3_inference.ipynb
# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç camera intrinsics!
```

---

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
My project/
‚îú‚îÄ‚îÄ Assets/
‚îÇ   ‚îú‚îÄ‚îÄ Scripts/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DatasetGenerator.cs      # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ü–µ–Ω —Å –æ–±—ä–µ–∫—Ç–∞–º–∏
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DatasetCapture.cs        # Quick capture (32 images)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ BatchDatasetCapture.cs   # Batch capture (1000 images)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Editor/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ DatasetCaptureEditor.cs
‚îÇ   ‚îî‚îÄ‚îÄ Shaders/
‚îÇ       ‚îî‚îÄ‚îÄ SegmentationShader.shader
‚îú‚îÄ‚îÄ strawberry_peduncle_segmentation/
‚îÇ   ‚îú‚îÄ‚îÄ dataset/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ images/          # RGB –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ masks/           # –¶–≤–µ—Ç–æ–≤—ã–µ –º–∞—Å–∫–∏ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ visualizations/  # –£—Å–∏–ª–µ–Ω–Ω—ã–µ –º–∞—Å–∫–∏ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ yolo/            # üÜï YOLO —Ñ–æ—Ä–º–∞—Ç (–∞–≤—Ç–æ–≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º—ã–π)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ images/      #    –ö–æ–ø–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ labels/      #    –¢–µ–∫—Å—Ç–æ–≤—ã–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ —Å –ø–æ–ª–∏–≥–æ–Ω–∞–º–∏
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dataset.yaml #    –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è YOLO
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ annotations.json # COCO –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ + —Å–≤—è–∑–∏
‚îÇ   ‚îú‚îÄ‚îÄ dataset_stats.py     # –ê–Ω–∞–ª–∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞
‚îÇ   ‚îî‚îÄ‚îÄ visualize_masks.py   # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –º–∞—Å–æ–∫
‚îú‚îÄ‚îÄ convert_to_yolo.py       # üÜï –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è COCO ‚Üí YOLO
‚îú‚îÄ‚îÄ affinity_net.py          # üß† AffinityNet –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
‚îú‚îÄ‚îÄ affinity_dataset.py      # üß† Dataset –¥–ª—è AffinityNet
‚îú‚îÄ‚îÄ train_affinity.py        # üß† Training pipeline
‚îú‚îÄ‚îÄ affinity_integration.py  # üß† –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –º–æ–¥–µ–ª—è–º–∏
‚îú‚îÄ‚îÄ train_affinity_net.ipynb # üß† Kaggle notebook –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
‚îú‚îÄ‚îÄ train_segmentation.ipynb # –û–±—É—á–µ–Ω–∏–µ Mask R-CNN
‚îú‚îÄ‚îÄ train_yolo11.ipynb       # üÜï –û–±—É—á–µ–Ω–∏–µ YOLOv11-seg
‚îú‚îÄ‚îÄ depth_estimation_inference.ipynb       # Depth Anything V2 + Mask R-CNN
‚îî‚îÄ‚îÄ depth_estimation_v3_inference.ipynb    # Depth Anything V3 + Auto Camera Intrinsics

```

---

## ‚ú® –ö–ª—é—á–µ–≤—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏

### –†–∞–Ω–¥–æ–º–∏–∑–∞—Ü–∏—è –∫–∞–º–µ—Ä—ã
- **–î–∏—Å—Ç–∞–Ω—Ü–∏—è:** 0.6–º - 1.2–º (–∞–¥–∞–ø—Ç–∏–≤–Ω–æ –ø–æ–¥ —Ä–∞–∑–º–µ—Ä —Å—Ü–µ–Ω—ã)
- **–£–≥–ª—ã:** –ê–∑–∏–º—É—Ç 0-360¬∞, —ç–ª–µ–≤–∞—Ü–∏—è 10-80¬∞
- **–ù–∞–∫–ª–æ–Ω:** Roll ¬±15¬∞
- **–ö—Ä–æ–ø—ã:** 30% –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º —Ä–∞–∑–º–µ—Ä–æ–º 50%
- **–ê–Ω—Ç–∏–∫–æ–ª–ª–∏–∑–∏—è:** –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –¥–æ –æ–±—ä–µ–∫—Ç–æ–≤, —É–≤–µ–ª–∏—á–µ–Ω–∏–µ —Ä–∞–¥–∏—É—Å–∞ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏

### –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –æ–∫–∫–ª—é–∑–∏–π
- –ü–æ–¥—Å—á—ë—Ç —Ä–µ–∞–ª—å–Ω—ã—Ö –≤–∏–¥–∏–º—ã—Ö –ø–∏–∫—Å–µ–ª–µ–π –Ω–∞ –º–∞—Å–∫–µ
- –û–±—ä–µ–∫—Ç –≤–∫–ª—é—á–∞–µ—Ç—Å—è –≤ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ `visibility_ratio >= 0.3`
- –ü–ª–æ—â–∞–¥—å (`area`) = –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∏–¥–∏–º—ã—Ö –ø–∏–∫—Å–µ–ª–µ–π

### –°–≤—è–∑–∏ –æ–±—ä–µ–∫—Ç–æ–≤
- –ö–∞–∂–¥—ã–π –ø–∞—Ä–∞–ª–ª–µ–ª–µ–ø–∏–ø–µ–¥ –∏–º–µ–µ—Ç `parent_id` ‚Üí `instance_id` —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–≥–æ –∫—É–±–∞
- –°–≤—è–∑—å —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
- –ú–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —Å–≤—è–∑–∏ —á–µ—Ä–µ–∑ –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫—É—é —ç–≤—Ä–∏—Å—Ç–∏–∫—É

---

## üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∏

### BatchDatasetCapture

```csharp
totalImages = 1000          // –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
imagesPerScene = 10         // –°–Ω–∏–º–∫–æ–≤ —Å –æ–¥–Ω–æ–π —Å—Ü–µ–Ω—ã
minOrbitRadius = 0.6f       // –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–¥–∏—É—Å –∫–∞–º–µ—Ä—ã
maxOrbitRadius = 1.2f       // –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–¥–∏—É—Å
cropProbability = 0.3f      // –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∫—Ä–æ–ø–∞
minVisibilityRatio = 0.3f   // –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –≤–∏–¥–∏–º–æ—Å—Ç—å –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è
```

### train_segmentation.ipynb

```python
NUM_EPOCHS = 30
BATCH_SIZE = 4
LEARNING_RATE = 0.005
TRAIN_RATIO = 0.8
```

---

## üìù –ü—Ä–∏–º–µ—á–∞–Ω–∏—è

1. **–†–∞–∑–º–µ—Ä –ø–∞—Ä–∞–ª–ª–µ–ª–µ–ø–∏–ø–µ–¥–∞:** –ò–∑–º–µ–Ω—ë–Ω —Å 0.1√ó0.1√ó2 —Å–º –¥–æ 0.3√ó0.3√ó2 —Å–º –¥–ª—è –ª—É—á—à–µ–π –≤–∏–¥–∏–º–æ—Å—Ç–∏
2. **–ú–∞—Å–∫–∏ —Ç—ë–º–Ω—ã–µ:** –ó–Ω–∞—á–µ–Ω–∏—è instance_id –æ—Ç 1-14 –≤—ã–≥–ª—è–¥—è—Ç —á—ë—Ä–Ω—ã–º–∏, –∏—Å–ø–æ–ª—å–∑—É–π –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
3. **parent_id —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å instance_id:** –û–±–∞ –æ–±—ä–µ–∫—Ç–∞ (–∫—É–± –∏ –ø–∞—Ä–∞–ª–ª–µ–ª–µ–ø–∏–ø–µ–¥) –∏–º–µ—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π instance_id
4. **–û–∫–∫–ª—é–∑–∏–∏ —É—á—Ç–µ–Ω—ã:** –ï—Å–ª–∏ –æ–±—ä –µ–∫—Ç –ø–µ—Ä–µ–∫—Ä—ã—Ç –±–æ–ª–µ–µ —á–µ–º –Ω–∞ 70%, –æ–Ω –Ω–µ –ø–æ–ø–∞–¥–∞–µ—Ç –≤ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏

---

## üéØ –¶–µ–ª—å –ø—Ä–æ–µ–∫—Ç–∞

–û–±—É—á–∏—Ç—å –Ω–µ–π—Ä–æ—Å–µ—Ç—å:
1. **–û–±–Ω–∞—Ä—É–∂–∏–≤–∞—Ç—å** –∫—Ä–∞—Å–Ω—ã–µ –∫—É–±—ã –∏ –∑–µ–ª—ë–Ω—ã–µ –ø–∞—Ä–∞–ª–ª–µ–ª–µ–ø–∏–ø–µ–¥—ã
2. **–°–µ–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å** –∫–∞–∂–¥—ã–π –æ–±—ä–µ–∫—Ç –æ—Ç–¥–µ–ª—å–Ω–æ (instance segmentation)
3. **–û–ø—Ä–µ–¥–µ–ª—è—Ç—å —Å–≤—è–∑—å** –∫–∞–∫–æ–π –ø–∞—Ä–∞–ª–ª–µ–ª–µ–ø–∏–ø–µ–¥ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∏—Ç –∫–∞–∫–æ–º—É –∫—É–±—É
