{
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        },
        "kaggle": {
            "accelerator": "gpu",
            "dataSources": [],
            "isGpuEnabled": true
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üìè Depth Estimation —Å Depth Anything V2 + Segmentation\n",
                "\n",
                "–≠—Ç–æ—Ç notebook:\n",
                "1. **–ó–∞–≥—Ä—É–∂–∞–µ—Ç Depth Anything V2 Metric** –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –≥–ª—É–±–∏–Ω—ã –≤ –º–µ—Ç—Ä–∞—Ö\n",
                "2. **–ò—Å–ø–æ–ª—å–∑—É–µ—Ç Mask R-CNN** –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∫—É–±–æ–≤ –∏ –ø–∞—Ä–∞–ª–ª–µ–ª–µ–ø–∏–ø–µ–¥–æ–≤\n",
                "3. **–í—ã—á–∏—Å–ª—è–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è** –¥–æ –∫–∞–∂–¥–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞\n",
                "4. **–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å–≤—è–∑–∏** –º–µ–∂–¥—É –ø–∞—Ä–∞–ª–ª–µ–ª–µ–ø–∏–ø–µ–¥–∞–º–∏ –∏ –∫—É–±–∞–º–∏\n",
                "5. **–í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ—Ç** —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å depth map –∏ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è–º–∏\n",
                "\n",
                "## üéØ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–∞–º–µ—Ä—ã –∏–∑ Unity\n",
                "\n",
                "–î–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –º–µ—Ç—Ä–∏—á–µ—Å–∫–æ–π –≥–ª—É–±–∏–Ω—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã Unity –∫–∞–º–µ—Ä—ã:\n",
                "- **FOV**: 60¬∞ (–≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–π)\n",
                "- **Resolution**: 1024√ó1024\n",
                "- **Focal Length**: ~886.4 –ø–∏–∫—Å–µ–ª–µ–π"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Depth Anything V2\n",
                "!git clone https://github.com/DepthAnything/Depth-Anything-V2\n",
                "!cd Depth-Anything-V2/metric_depth && pip install -r requirements.txt\n",
                "\n",
                "# Segmentation\n",
                "!pip install torch torchvision\n",
                "!pip install pycocotools\n",
                "!pip install opencv-python-headless\n",
                "!pip install matplotlib\n",
                "!pip install scipy\n",
                "!pip install open3d"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "sys.path.append('Depth-Anything-V2/metric_depth')\n",
                "\n",
                "import os\n",
                "import json\n",
                "import numpy as np\n",
                "import cv2\n",
                "from PIL import Image\n",
                "import matplotlib.pyplot as plt\n",
                "from collections import defaultdict\n",
                "import math\n",
                "\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "import torchvision\n",
                "from torchvision.models.detection import maskrcnn_resnet50_fpn, MaskRCNN_ResNet50_FPN_Weights\n",
                "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
                "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
                "\n",
                "from depth_anything_v2.dpt import DepthAnythingV2\n",
                "\n",
                "print(f\"PyTorch version: {torch.__version__}\")\n",
                "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# –ü—É—Ç–∏ –∫ –¥–∞–Ω–Ω—ã–º\n",
                "DATASET_PATH = \"/kaggle/input/strawberry-peduncle-segmentation\"\n",
                "IMAGES_PATH = os.path.join(DATASET_PATH, \"images\")\n",
                "ANNOTATIONS_PATH = os.path.join(DATASET_PATH, \"annotations.json\")\n",
                "\n",
                "# –ü—É—Ç—å –∫ –æ–±—É—á–µ–Ω–Ω–æ–π Mask R-CNN\n",
                "SEGMENTATION_MODEL_PATH = \"/kaggle/input/cube-segmentation-model/best_model.pth\"\n",
                "\n",
                "# Unity Camera –ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
                "UNITY_FOV_VERTICAL = 60.0  # –≥—Ä–∞–¥—É—Å—ã\n",
                "IMAGE_WIDTH = 1024\n",
                "IMAGE_HEIGHT = 1024\n",
                "\n",
                "# –í—ã—á–∏—Å–ª–µ–Ω–∏–µ focal length –∏–∑ Unity FOV\n",
                "fov_rad = UNITY_FOV_VERTICAL * math.pi / 180.0\n",
                "FOCAL_LENGTH_Y = (IMAGE_HEIGHT / 2.0) / math.tan(fov_rad / 2.0)\n",
                "FOCAL_LENGTH_X = FOCAL_LENGTH_Y  # Square aspect ratio\n",
                "\n",
                "print(f\"üì∑ Unity Camera Intrinsics:\")\n",
                "print(f\"   FOV: {UNITY_FOV_VERTICAL}¬∞\")\n",
                "print(f\"   Resolution: {IMAGE_WIDTH}√ó{IMAGE_HEIGHT}\")\n",
                "print(f\"   Focal Length: {FOCAL_LENGTH_X:.2f} pixels\")\n",
                "\n",
                "# Depth Anything V2 –Ω–∞—Å—Ç—Ä–æ–π–∫–∏\n",
                "DEPTH_ENCODER = 'vitl'  # vits, vitb, vitl\n",
                "DEPTH_DATASET = 'hypersim'  # 'hypersim' –¥–ª—è indoor, 'vkitti' –¥–ª—è outdoor\n",
                "MAX_DEPTH = 20.0  # 20m –¥–ª—è indoor, 80m –¥–ª—è outdoor\n",
                "\n",
                "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "\n",
                "# –ö–∞—Ç–µ–≥–æ—Ä–∏–∏\n",
                "CATEGORIES = {\n",
                "    0: \"background\",\n",
                "    1: \"red_cube\",\n",
                "    2: \"green_parallelepiped\"\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# –°–∫–∞—á–∏–≤–∞–Ω–∏–µ Depth Anything V2 Metric –º–æ–¥–µ–ª–∏\n",
                "depth_model_url = f\"https://huggingface.co/depth-anything/Depth-Anything-V2-Metric-Hypersim-Large/resolve/main/depth_anything_v2_metric_hypersim_vitl.pth\"\n",
                "depth_model_path = \"depth_anything_v2_metric_hypersim_vitl.pth\"\n",
                "\n",
                "if not os.path.exists(depth_model_path):\n",
                "    print(f\"Downloading Depth Anything V2 model...\")\n",
                "    !wget {depth_model_url} -O {depth_model_path}\n",
                "else:\n",
                "    print(f\"Depth model already downloaded.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Depth Anything V2\n",
                "model_configs = {\n",
                "    'vits': {'encoder': 'vits', 'features': 64, 'out_channels': [48, 96, 192, 384]},\n",
                "    'vitb': {'encoder': 'vitb', 'features': 128, 'out_channels': [96, 192, 384, 768]},\n",
                "    'vitl': {'encoder': 'vitl', 'features': 256, 'out_channels': [256, 512, 1024, 1024]}\n",
                "}\n",
                "\n",
                "depth_model = DepthAnythingV2(**{**model_configs[DEPTH_ENCODER], 'max_depth': MAX_DEPTH})\n",
                "depth_model.load_state_dict(torch.load(depth_model_path, map_location='cpu'))\n",
                "depth_model = depth_model.to(DEVICE).eval()\n",
                "\n",
                "print(\"‚úÖ Depth Anything V2 loaded\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# –ó–∞–≥—Ä—É–∑–∫–∞ Mask R-CNN –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏\n",
                "def get_segmentation_model(num_classes):\n",
                "    model = maskrcnn_resnet50_fpn(weights=None)\n",
                "    \n",
                "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
                "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
                "    \n",
                "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
                "    hidden_layer = 256\n",
                "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes)\n",
                "    \n",
                "    return model\n",
                "\n",
                "segmentation_model = get_segmentation_model(num_classes=3)\n",
                "segmentation_model.load_state_dict(torch.load(SEGMENTATION_MODEL_PATH, map_location='cpu'))\n",
                "segmentation_model = segmentation_model.to(DEVICE).eval()\n",
                "\n",
                "print(\"‚úÖ Mask R-CNN loaded\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def predict_depth(image_bgr):\n",
                "    \"\"\"\n",
                "    –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç depth map –≤ –º–µ—Ç—Ä–∞—Ö.\n",
                "    \n",
                "    Args:\n",
                "        image_bgr: BGR –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (OpenCV format)\n",
                "    \n",
                "    Returns:\n",
                "        depth_map: (H, W) numpy array —Å –≥–ª—É–±–∏–Ω–æ–π –≤ –º–µ—Ç—Ä–∞—Ö\n",
                "    \"\"\"\n",
                "    with torch.no_grad():\n",
                "        depth = depth_model.infer_image(image_bgr, IMAGE_HEIGHT)\n",
                "    \n",
                "    return depth\n",
                "\n",
                "\n",
                "def predict_segmentation(image_rgb, score_threshold=0.5):\n",
                "    \"\"\"\n",
                "    –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é –æ–±—ä–µ–∫—Ç–æ–≤.\n",
                "    \n",
                "    Args:\n",
                "        image_rgb: RGB –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (PIL/numpy format)\n",
                "        score_threshold: –ü–æ—Ä–æ–≥ confidence\n",
                "    \n",
                "    Returns:\n",
                "        prediction: dict —Å boxes, labels, scores, masks\n",
                "    \"\"\"\n",
                "    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Ç–µ–Ω–∑–æ—Ä\n",
                "    if isinstance(image_rgb, np.ndarray):\n",
                "        image_tensor = torch.as_tensor(image_rgb, dtype=torch.float32).permute(2, 0, 1) / 255.0\n",
                "    else:\n",
                "        image_tensor = torch.as_tensor(np.array(image_rgb), dtype=torch.float32).permute(2, 0, 1) / 255.0\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        prediction = segmentation_model([image_tensor.to(DEVICE)])[0]\n",
                "    \n",
                "    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ score\n",
                "    keep = prediction['scores'] >= score_threshold\n",
                "    filtered = {\n",
                "        'boxes': prediction['boxes'][keep].cpu(),\n",
                "        'labels': prediction['labels'][keep].cpu(),\n",
                "        'scores': prediction['scores'][keep].cpu(),\n",
                "        'masks': prediction['masks'][keep].cpu()\n",
                "    }\n",
                "    \n",
                "    return filtered\n",
                "\n",
                "\n",
                "def predict_associations(boxes, labels, scores):\n",
                "    \"\"\"\n",
                "    –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —Å–≤—è–∑–∏ –º–µ–∂–¥—É –ø–∞—Ä–∞–ª–ª–µ–ª–µ–ø–∏–ø–µ–¥–∞–º–∏ –∏ –∫—É–±–∞–º–∏.\n",
                "    \"\"\"\n",
                "    boxes_np = boxes.numpy() if isinstance(boxes, torch.Tensor) else boxes\n",
                "    labels_np = labels.numpy() if isinstance(labels, torch.Tensor) else labels\n",
                "    scores_np = scores.numpy() if isinstance(scores, torch.Tensor) else scores\n",
                "    \n",
                "    cube_indices = np.where(labels_np == 1)[0]\n",
                "    para_indices = np.where(labels_np == 2)[0]\n",
                "    \n",
                "    associations = {}\n",
                "    \n",
                "    for para_idx in para_indices:\n",
                "        para_box = boxes_np[para_idx]\n",
                "        para_center_x = (para_box[0] + para_box[2]) / 2\n",
                "        para_bottom = para_box[3]\n",
                "        \n",
                "        min_dist = float('inf')\n",
                "        best_cube_idx = None\n",
                "        \n",
                "        for cube_idx in cube_indices:\n",
                "            cube_box = boxes_np[cube_idx]\n",
                "            cube_center_x = (cube_box[0] + cube_box[2]) / 2\n",
                "            cube_top = cube_box[1]\n",
                "            \n",
                "            vertical_dist = abs(para_bottom - cube_top)\n",
                "            horizontal_dist = abs(para_center_x - cube_center_x)\n",
                "            \n",
                "            dist = np.sqrt(vertical_dist**2 + horizontal_dist**2)\n",
                "            \n",
                "            # –ë–æ–Ω—É—Å –µ—Å–ª–∏ –ø–∞—Ä–∞–ª–ª–µ–ª–µ–ø–∏–ø–µ–¥ –ø–æ —Ü–µ–Ω—Ç—Ä—É –∫—É–±–∞\n",
                "            if cube_box[0] <= para_center_x <= cube_box[2]:\n",
                "                dist *= 0.5\n",
                "            \n",
                "            if dist < min_dist:\n",
                "                min_dist = dist\n",
                "                best_cube_idx = cube_idx\n",
                "        \n",
                "        associations[int(para_idx)] = int(best_cube_idx) if best_cube_idx is not None else None\n",
                "    \n",
                "    return associations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def calculate_object_distance(depth_map, mask, boxes, idx):\n",
                "    \"\"\"\n",
                "    –í—ã—á–∏—Å–ª—è–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ –æ–±—ä–µ–∫—Ç–∞ –∏—Å–ø–æ–ª—å–∑—É—è depth map –∏ –º–∞—Å–∫—É.\n",
                "    \n",
                "    Args:\n",
                "        depth_map: (H, W) depth –≤ –º–µ—Ç—Ä–∞—Ö\n",
                "        mask: (H, W) –±–∏–Ω–∞—Ä–Ω–∞—è –º–∞—Å–∫–∞ –æ–±—ä–µ–∫—Ç–∞\n",
                "        boxes: bounding boxes\n",
                "        idx: –∏–Ω–¥–µ–∫—Å –æ–±—ä–µ–∫—Ç–∞\n",
                "    \n",
                "    Returns:\n",
                "        distance_info: dict —Å min, max, mean, median —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è–º–∏\n",
                "    \"\"\"\n",
                "    # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–∞—Å–∫—É\n",
                "    if isinstance(mask, torch.Tensor):\n",
                "        obj_mask = mask[idx, 0].numpy() > 0.5\n",
                "    else:\n",
                "        obj_mask = mask > 0.5\n",
                "    \n",
                "    # –ü–æ–ª—É—á–∞–µ–º –≥–ª—É–±–∏–Ω—ã —Ç–æ–ª—å–∫–æ –¥–ª—è –ø–∏–∫—Å–µ–ª–µ–π –æ–±—ä–µ–∫—Ç–∞\n",
                "    object_depths = depth_map[obj_mask]\n",
                "    \n",
                "    if len(object_depths) == 0:\n",
                "        return {\n",
                "            'min': 0.0,\n",
                "            'max': 0.0,\n",
                "            'mean': 0.0,\n",
                "            'median': 0.0,\n",
                "            'center': 0.0\n",
                "        }\n",
                "    \n",
                "    # –¢–∞–∫–∂–µ –≤—ã—á–∏—Å–ª—è–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ —Ü–µ–Ω—Ç—Ä–∞ bbox\n",
                "    box = boxes[idx].numpy() if isinstance(boxes[idx], torch.Tensor) else boxes[idx]\n",
                "    center_y = int((box[1] + box[3]) / 2)\n",
                "    center_x = int((box[0] + box[2]) / 2)\n",
                "    center_depth = depth_map[center_y, center_x]\n",
                "    \n",
                "    return {\n",
                "        'min': float(np.min(object_depths)),\n",
                "        'max': float(np.max(object_depths)),\n",
                "        'mean': float(np.mean(object_depths)),\n",
                "        'median': float(np.median(object_depths)),\n",
                "        'center': float(center_depth)\n",
                "    }"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. –ü–æ–ª–Ω—ã–π inference pipeline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def full_inference(image_path, visualize=True):\n",
                "    \"\"\"\n",
                "    –ü–æ–ª–Ω—ã–π pipeline: depth estimation + segmentation + associations + distances.\n",
                "    \n",
                "    Args:\n",
                "        image_path: –ø—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é\n",
                "        visualize: –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –ª–∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é\n",
                "    \n",
                "    Returns:\n",
                "        results: dict —Å depth_map, segmentation, associations, distances\n",
                "    \"\"\"\n",
                "    # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
                "    image_rgb = np.array(Image.open(image_path).convert('RGB'))\n",
                "    image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)\n",
                "    \n",
                "    print(f\"üì∏ Processing: {os.path.basename(image_path)}\")\n",
                "    \n",
                "    # 2. Depth estimation\n",
                "    print(\"   üîç Estimating depth...\")\n",
                "    depth_map = predict_depth(image_bgr)\n",
                "    \n",
                "    # 3. Segmentation\n",
                "    print(\"   üéØ Segmenting objects...\")\n",
                "    segmentation = predict_segmentation(image_rgb)\n",
                "    \n",
                "    # 4. Associations\n",
                "    print(\"   üîó Predicting associations...\")\n",
                "    associations = predict_associations(\n",
                "        segmentation['boxes'],\n",
                "        segmentation['labels'],\n",
                "        segmentation['scores']\n",
                "    )\n",
                "    \n",
                "    # 5. Calculate distances for each object\n",
                "    print(\"   üìè Calculating distances...\")\n",
                "    distances = []\n",
                "    for i in range(len(segmentation['labels'])):\n",
                "        dist_info = calculate_object_distance(\n",
                "            depth_map,\n",
                "            segmentation['masks'],\n",
                "            segmentation['boxes'],\n",
                "            i\n",
                "        )\n",
                "        distances.append(dist_info)\n",
                "    \n",
                "    # 6. Summary\n",
                "    n_cubes = (segmentation['labels'] == 1).sum().item()\n",
                "    n_paras = (segmentation['labels'] == 2).sum().item()\n",
                "    \n",
                "    print(f\"\\n   ‚úÖ Results:\")\n",
                "    print(f\"      Cubes: {n_cubes}\")\n",
                "    print(f\"      Parallelepipeds: {n_paras}\")\n",
                "    print(f\"      Associations: {len(associations)}\")\n",
                "    print(f\"      Depth range: {depth_map.min():.2f}m - {depth_map.max():.2f}m\")\n",
                "    \n",
                "    # 7. Visualization\n",
                "    if visualize:\n",
                "        visualize_results(\n",
                "            image_rgb,\n",
                "            depth_map,\n",
                "            segmentation,\n",
                "            associations,\n",
                "            distances\n",
                "        )\n",
                "    \n",
                "    return {\n",
                "        'image': image_rgb,\n",
                "        'depth_map': depth_map,\n",
                "        'segmentation': segmentation,\n",
                "        'associations': associations,\n",
                "        'distances': distances\n",
                "    }"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def visualize_results(image, depth_map, segmentation, associations, distances):\n",
                "    \"\"\"\n",
                "    –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã: RGB, depth, segmentation, distances.\n",
                "    \"\"\"\n",
                "    fig, axes = plt.subplots(2, 2, figsize=(18, 16))\n",
                "    \n",
                "    boxes = segmentation['boxes'].numpy()\n",
                "    labels = segmentation['labels'].numpy()\n",
                "    scores = segmentation['scores'].numpy()\n",
                "    masks = segmentation['masks'].numpy()\n",
                "    \n",
                "    # 1. Original RGB\n",
                "    axes[0, 0].imshow(image)\n",
                "    axes[0, 0].set_title('Original Image', fontsize=14, fontweight='bold')\n",
                "    axes[0, 0].axis('off')\n",
                "    \n",
                "    # 2. Depth Map\n",
                "    depth_vis = axes[0, 1].imshow(depth_map, cmap='turbo', vmin=0, vmax=MAX_DEPTH)\n",
                "    axes[0, 1].set_title(f'Depth Map (0-{MAX_DEPTH}m)', fontsize=14, fontweight='bold')\n",
                "    axes[0, 1].axis('off')\n",
                "    plt.colorbar(depth_vis, ax=axes[0, 1], fraction=0.046, pad=0.04, label='Depth (m)')\n",
                "    \n",
                "    # 3. Segmentation with distances\n",
                "    axes[1, 0].imshow(image)\n",
                "    \n",
                "    colors = {1: 'red', 2: 'green'}\n",
                "    \n",
                "    for i in range(len(labels)):\n",
                "        box = boxes[i]\n",
                "        label = labels[i]\n",
                "        score = scores[i]\n",
                "        dist = distances[i]\n",
                "        color = colors.get(label, 'blue')\n",
                "        \n",
                "        # Draw bbox\n",
                "        rect = plt.Rectangle(\n",
                "            (box[0], box[1]), box[2] - box[0], box[3] - box[1],\n",
                "            fill=False, edgecolor=color, linewidth=2\n",
                "        )\n",
                "        axes[1, 0].add_patch(rect)\n",
                "        \n",
                "        # Draw label with distance\n",
                "        text = f\"{CATEGORIES[label]}\\n{dist['center']:.2f}m\"\n",
                "        axes[1, 0].text(\n",
                "            box[0], box[1] - 10,\n",
                "            text,\n",
                "            color='white',\n",
                "            fontsize=10,\n",
                "            bbox=dict(boxstyle='round', facecolor=color, alpha=0.8)\n",
                "        )\n",
                "    \n",
                "    axes[1, 0].set_title('Segmentation + Distances', fontsize=14, fontweight='bold')\n",
                "    axes[1, 0].axis('off')\n",
                "    \n",
                "    # 4. Masks with associations\n",
                "    axes[1, 1].imshow(image)\n",
                "    \n",
                "    # Draw masks\n",
                "    combined_mask = np.zeros((*image.shape[:2], 3))\n",
                "    for i in range(len(labels)):\n",
                "        mask = masks[i, 0] > 0.5\n",
                "        label = labels[i]\n",
                "        \n",
                "        if label == 1:  # Cube\n",
                "            combined_mask[mask] = [1, 0, 0]\n",
                "        elif label == 2:  # Parallelepiped\n",
                "            combined_mask[mask] = [0, 1, 0]\n",
                "    \n",
                "    axes[1, 1].imshow(combined_mask, alpha=0.5)\n",
                "    \n",
                "    # Draw association lines\n",
                "    for para_idx, cube_idx in associations.items():\n",
                "        if cube_idx is not None:\n",
                "            para_box = boxes[para_idx]\n",
                "            cube_box = boxes[cube_idx]\n",
                "            \n",
                "            para_center = [(para_box[0] + para_box[2]) / 2, (para_box[1] + para_box[3]) / 2]\n",
                "            cube_center = [(cube_box[0] + cube_box[2]) / 2, (cube_box[1] + cube_box[3]) / 2]\n",
                "            \n",
                "            axes[1, 1].plot(\n",
                "                [para_center[0], cube_center[0]],\n",
                "                [para_center[1], cube_center[1]],\n",
                "                'y-', linewidth=2\n",
                "            )\n",
                "            axes[1, 1].plot(*para_center, 'yo', markersize=8)\n",
                "            axes[1, 1].plot(*cube_center, 'yo', markersize=8)\n",
                "    \n",
                "    axes[1, 1].set_title('Masks + Associations', fontsize=14, fontweight='bold')\n",
                "    axes[1, 1].axis('off')\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "    \n",
                "    # Print detailed distances\n",
                "    print(\"\\nüìä Detailed Distance Information:\")\n",
                "    print(\"=\" * 80)\n",
                "    for i in range(len(labels)):\n",
                "        label_name = CATEGORIES[labels[i]]\n",
                "        dist = distances[i]\n",
                "        parent_info = \"\"\n",
                "        \n",
                "        if i in associations:\n",
                "            parent_idx = associations[i]\n",
                "            if parent_idx is not None:\n",
                "                parent_dist = distances[parent_idx]\n",
                "                parent_info = f\" ‚Üí Parent cube at {parent_dist['center']:.2f}m\"\n",
                "        \n",
                "        print(f\"[{i}] {label_name}:\")\n",
                "        print(f\"    Center: {dist['center']:.3f}m | Mean: {dist['mean']:.3f}m | \"\n",
                "              f\"Range: {dist['min']:.3f}m - {dist['max']:.3f}m{parent_info}\")\n",
                "    print(\"=\" * 80)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. –ó–∞–ø—É—Å–∫ inference –Ω–∞ –ø—Ä–∏–º–µ—Ä–∞—Ö"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n",
                "import glob\n",
                "\n",
                "image_files = sorted(glob.glob(os.path.join(IMAGES_PATH, \"*.png\")))[:5]\n",
                "\n",
                "print(f\"Found {len(image_files)} images for inference\\n\")\n",
                "\n",
                "# –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ\n",
                "all_results = []\n",
                "\n",
                "for img_path in image_files:\n",
                "    print(\"\\n\" + \"=\"*80)\n",
                "    results = full_inference(img_path, visualize=True)\n",
                "    all_results.append(results)\n",
                "    print(\"=\"*80)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≤—Å–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É\n",
                "all_cube_distances = []\n",
                "all_para_distances = []\n",
                "\n",
                "for result in all_results:\n",
                "    labels = result['segmentation']['labels'].numpy()\n",
                "    distances = result['distances']\n",
                "    \n",
                "    for i, label in enumerate(labels):\n",
                "        if label == 1:  # Cube\n",
                "            all_cube_distances.append(distances[i]['center'])\n",
                "        elif label == 2:  # Parallelepiped\n",
                "            all_para_distances.append(distances[i]['center'])\n",
                "\n",
                "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "axes[0].hist(all_cube_distances, bins=20, color='red', alpha=0.7, edgecolor='black')\n",
                "axes[0].set_title('Distance Distribution: Red Cubes', fontsize=14, fontweight='bold')\n",
                "axes[0].set_xlabel('Distance (m)')\n",
                "axes[0].set_ylabel('Count')\n",
                "axes[0].grid(True, alpha=0.3)\n",
                "\n",
                "axes[1].hist(all_para_distances, bins=20, color='green', alpha=0.7, edgecolor='black')\n",
                "axes[1].set_title('Distance Distribution: Green Parallelepipeds', fontsize=14, fontweight='bold')\n",
                "axes[1].set_xlabel('Distance (m)')\n",
                "axes[1].set_ylabel('Count')\n",
                "axes[1].grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(f\"\\nüìà Overall Statistics:\")\n",
                "print(f\"   Cubes: {len(all_cube_distances)} detected\")\n",
                "print(f\"      Mean distance: {np.mean(all_cube_distances):.3f}m\")\n",
                "print(f\"      Std: {np.std(all_cube_distances):.3f}m\")\n",
                "print(f\"      Range: {np.min(all_cube_distances):.3f}m - {np.max(all_cube_distances):.3f}m\")\n",
                "print(f\"\\n   Parallelepipeds: {len(all_para_distances)} detected\")\n",
                "print(f\"      Mean distance: {np.mean(all_para_distances):.3f}m\")\n",
                "print(f\"      Std: {np.std(all_para_distances):.3f}m\")\n",
                "print(f\"      Range: {np.min(all_para_distances):.3f}m - {np.max(all_para_distances):.3f}m\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ JSON\n",
                "output_results = []\n",
                "\n",
                "for i, (img_path, result) in enumerate(zip(image_files, all_results)):\n",
                "    labels = result['segmentation']['labels'].numpy()\n",
                "    boxes = result['segmentation']['boxes'].numpy()\n",
                "    scores = result['segmentation']['scores'].numpy()\n",
                "    distances = result['distances']\n",
                "    associations = result['associations']\n",
                "    \n",
                "    objects = []\n",
                "    for j in range(len(labels)):\n",
                "        obj = {\n",
                "            'id': j,\n",
                "            'category': CATEGORIES[labels[j]],\n",
                "            'bbox': boxes[j].tolist(),\n",
                "            'score': float(scores[j]),\n",
                "            'distance': {\n",
                "                'center': distances[j]['center'],\n",
                "                'mean': distances[j]['mean'],\n",
                "                'min': distances[j]['min'],\n",
                "                'max': distances[j]['max']\n",
                "            }\n",
                "        }\n",
                "        \n",
                "        if j in associations:\n",
                "            obj['parent_id'] = associations[j]\n",
                "        \n",
                "        objects.append(obj)\n",
                "    \n",
                "    output_results.append({\n",
                "        'image': os.path.basename(img_path),\n",
                "        'depth_range': {\n",
                "            'min': float(result['depth_map'].min()),\n",
                "            'max': float(result['depth_map'].max()),\n",
                "            'mean': float(result['depth_map'].mean())\n",
                "        },\n",
                "        'objects': objects\n",
                "    })\n",
                "\n",
                "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ\n",
                "with open('depth_segmentation_results.json', 'w') as f:\n",
                "    json.dump(output_results, f, indent=2)\n",
                "\n",
                "print(\"‚úÖ Results saved to depth_segmentation_results.json\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìù –†–µ–∑—é–º–µ\n",
                "\n",
                "### –ß—Ç–æ –¥–µ–ª–∞–µ—Ç —ç—Ç–æ—Ç notebook:\n",
                "\n",
                "1. **Depth Estimation**: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç Depth Anything V2 Metric –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≥–ª—É–±–∏–Ω—ã –≤ –º–µ—Ç—Ä–∞—Ö\n",
                "2. **Segmentation**: Mask R-CNN –Ω–∞—Ö–æ–¥–∏—Ç –∏ —Å–µ–≥–º–µ–Ω—Ç–∏—Ä—É–µ—Ç –∫—É–±—ã –∏ –ø–∞—Ä–∞–ª–ª–µ–ª–µ–ø–∏–ø–µ–¥—ã\n",
                "3. **Associations**: –ì–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å–≤—è–∑–∏\n",
                "4. **Distance Calculation**: –î–ª—è –∫–∞–∂–¥–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞ –≤—ã—á–∏—Å–ª—è–µ—Ç—Å—è —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ –∫–∞–º–µ—Ä—ã\n",
                "\n",
                "### –ü–∞—Ä–∞–º–µ—Ç—Ä—ã Unity –∫–∞–º–µ—Ä—ã:\n",
                "\n",
                "- **FOV**: 60¬∞ ‚Üí Focal Length: ~886.4 –ø–∏–∫—Å–µ–ª–µ–π\n",
                "- **Resolution**: 1024√ó1024\n",
                "- –≠—Ç–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –º–µ—Ç—Ä–∏—á–µ—Å–∫–æ–π –≥–ª—É–±–∏–Ω—ã\n",
                "\n",
                "### –¢–æ—á–Ω–æ—Å—Ç—å:\n",
                "\n",
                "- Depth Anything V2 –æ–±—É—á–µ–Ω–∞ –Ω–∞ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö (Hypersim)\n",
                "- –†–∞–±–æ—Ç–∞–µ—Ç –¥–æ 20–º –¥–ª—è indoor —Å—Ü–µ–Ω\n",
                "- –¢–æ—á–Ω–æ—Å—Ç—å –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –∫–∞—á–µ—Å—Ç–≤–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –æ—Å–≤–µ—â–µ–Ω–∏—è\n",
                "\n",
                "### –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ:\n",
                "\n",
                "- –†–æ–±–æ—Ç–æ—Ç–µ—Ö–Ω–∏–∫–∞ (–Ω–∞–≤–∏–≥–∞—Ü–∏—è, –∑–∞—Ö–≤–∞—Ç –æ–±—ä–µ–∫—Ç–æ–≤)\n",
                "- AR/VR (—Ä–∞–∑–º–µ—â–µ–Ω–∏–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤)\n",
                "- –ê–≤—Ç–æ–Ω–æ–º–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã (–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–µ–ø—è—Ç—Å—Ç–≤–∏–π)\n",
                "- –ö–æ–Ω—Ç—Ä–æ–ª—å –∫–∞—á–µ—Å—Ç–≤–∞ (–∏–∑–º–µ—Ä–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–æ–≤)"
            ]
        }
    ]
}