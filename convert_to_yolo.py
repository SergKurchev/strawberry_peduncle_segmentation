#!/usr/bin/env python3
"""
–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è COCO Instance Segmentation –¥–∞—Ç–∞—Å–µ—Ç–∞ –≤ YOLO —Ñ–æ—Ä–º–∞—Ç.
–°–æ–∑–¥–∞—ë—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ —Å –ø–æ–ª–∏–≥–æ–Ω–∞–º–∏ –¥–ª—è YOLOv11-seg.
–û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç (PNG masks + COCO JSON) –æ—Å—Ç–∞—ë—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π.
"""

import os
import json
import cv2
import numpy as np
from pathlib import Path
from tqdm import tqdm


def mask_to_polygons(mask_path, instance_id, category_id):
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç PNG –º–∞—Å–∫—É –≤ YOLO –ø–æ–ª–∏–≥–æ–Ω—ã.
    
    Args:
        mask_path: –ø—É—Ç—å –∫ PNG –º–∞—Å–∫–µ
        instance_id: ID –∏–Ω—Å—Ç–∞–Ω—Å–∞
        category_id: ID –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    
    Returns:
        list of polygons: –∫–∞–∂–¥—ã–π –ø–æ–ª–∏–≥–æ–Ω —ç—Ç–æ —Å–ø–∏—Å–æ–∫ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
    """
    # –ß–∏—Ç–∞–µ–º –º–∞—Å–∫—É
    mask_img = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)
    
    if mask_img is None:
        print(f"‚ö†Ô∏è Warning: Could not read mask {mask_path}")
        return []
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç RGB (channel encoding)
    # R –∫–∞–Ω–∞–ª = instance_id, G –∫–∞–Ω–∞–ª = category_id
    if len(mask_img.shape) == 3:
        r_channel = mask_img[: , :, 2]  # OpenCV uses BGR
        g_channel = mask_img[:, :, 1]
        
        # –°–æ–∑–¥–∞—ë–º –±–∏–Ω–∞—Ä–Ω—É—é –º–∞—Å–∫—É –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ instance + category
        binary_mask = (r_channel == instance_id) & (g_channel == category_id)
    else:
        # Grayscale mask - –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞–ø—Ä—è–º—É—é
        binary_mask = mask_img == instance_id
    
    # –ü—Ä–∏–≤–æ–¥–∏–º –∫ uint8
    binary_mask = binary_mask.astype(np.uint8) * 255
    
    # –ù–∞—Ö–æ–¥–∏–º –∫–æ–Ω—Ç—É—Ä—ã
    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    if len(contours) == 0:
        return []
    
    height, width = binary_mask.shape
    polygons = []
    
    for contour in contours:
        # –ú–∏–Ω–∏–º—É–º 3 —Ç–æ—á–∫–∏ –¥–ª—è –ø–æ–ª–∏–≥–æ–Ω–∞
        if len(contour) < 3:
            continue
        
        # –£–ø—Ä–æ—â–∞–µ–º –ø–æ–ª–∏–≥–æ–Ω (Douglas-Peucker)
        epsilon = 0.001 * cv2.arcLength(contour, True)
        approx = cv2.approxPolyDP(contour, epsilon, True)
        
        if len(approx) < 3:
            continue
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã (0-1)
        polygon = []
        for point in approx:
            x_norm = point[0][0] / width
            y_norm = point[0][1] / height
            polygon.extend([x_norm, y_norm])
        
        polygons.append(polygon)
    
    return polygons


def convert_coco_to_yolo(dataset_path, output_path=None):
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç COCO –¥–∞—Ç–∞—Å–µ—Ç –≤ YOLO —Ñ–æ—Ä–º–∞—Ç.
    
    Args:
        dataset_path: –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –¥–∞—Ç–∞—Å–µ—Ç–æ–º (—Å–æ–¥–µ—Ä–∂–∏—Ç images/, masks/, annotations.json)
        output_path: –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è YOLO –¥–∞—Ç–∞—Å–µ—Ç–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: dataset_path/yolo)
    """
    dataset_path = Path(dataset_path)
    
    if output_path is None:
        output_path = dataset_path / "yolo"
    else:
        output_path = Path(output_path)
    
    # –ü—É—Ç–∏
    annotations_path = dataset_path / "annotations.json"
    images_path = dataset_path / "images"
    masks_path = dataset_path / "masks"
    
    # –°–æ–∑–¥–∞—ë–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É YOLO
    yolo_images_dir = output_path / "images"
    yolo_labels_dir = output_path / "labels"
    yolo_images_dir.mkdir(parents=True, exist_ok=True)
    yolo_labels_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"üìÇ Reading annotations from: {annotations_path}")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º COCO –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
    with open(annotations_path, 'r') as f:
        coco_data = json.load(f)
    
    # –ú–∞–ø–ø–∏–Ω–≥ –∫–∞—Ç–µ–≥–æ—Ä–∏–π (COCO ID -> YOLO class index)
    # –í YOLO –∫–ª–∞—Å—Å—ã –Ω–∞—á–∏–Ω–∞—é—Ç—Å—è —Å 0
    category_mapping = {}
    for idx, category in enumerate(coco_data['categories']):
        category_mapping[category['id']] = idx
    
    print(f"\nüìã Category Mapping (COCO ID -> YOLO Class):")
    for category in coco_data['categories']:
        yolo_class = category_mapping[category['id']]
        print(f"   {category['id']} ({category['name']}) -> {yolo_class}")
    
    # –°–æ–∑–¥–∞—ë–º dataset.yaml
    yaml_content = f"""# YOLO Dataset Configuration
# Generated from COCO format

path: {output_path.absolute()}
train: images  # –í—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
val: images    # –ú–æ–∂–Ω–æ —Ä–∞–∑–¥–µ–ª–∏—Ç—å –Ω–∞ train/val –ø–æ–∑–∂–µ

# Classes
names:
"""
    
    for category in sorted(coco_data['categories'], key=lambda x: category_mapping[x['id']]):
        yolo_class = category_mapping[category['id']]
        yaml_content += f"  {yolo_class}: {category['name']}\n"
    
    yaml_path = output_path / "dataset.yaml"
    with open(yaml_path, 'w') as f:
        f.write(yaml_content)
    
    print(f"\n‚úÖ Created dataset.yaml: {yaml_path}")
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º
    image_annotations = {}
    for ann in coco_data['annotations']:
        image_id = ann['image_id']
        if image_id not in image_annotations:
            image_annotations[image_id] = []
        image_annotations[image_id].append(ann)
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∫–∞–∂–¥–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    print(f"\nüîÑ Converting {len(coco_data['images'])} images...")
    
    for image_info in tqdm(coco_data['images']):
        image_id = image_info['id']
        filename = image_info['file_name']
        
        # –ö–æ–ø–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (—Å–æ–∑–¥–∞—ë–º —Å–∏–º–≤–æ–ª–∏—á–µ—Å–∫—É—é —Å—Å—ã–ª–∫—É –∏–ª–∏ –∫–æ–ø–∏—Ä—É–µ–º)
        src_image = images_path / filename
        dst_image = yolo_images_dir / filename
        
        if src_image.exists():
            if not dst_image.exists():
                # Windows: –∫–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª
                import shutil
                shutil.copy2(src_image, dst_image)
        else:
            print(f"‚ö†Ô∏è Warning: Image not found: {src_image}")
            continue
        
        # –°–æ–∑–¥–∞—ë–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª —Å –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è–º–∏
        label_filename = filename.replace('.png', '.txt').replace('.jpg', '.txt')
        label_path = yolo_labels_dir / label_filename
        
        # –ü–æ–ª—É—á–∞–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –¥–ª—è —ç—Ç–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        annotations = image_annotations.get(image_id, [])
        
        with open(label_path, 'w') as f:
            for ann in annotations:
                instance_id = ann['instance_id']
                category_id = ann['category_id']
                yolo_class = category_mapping[category_id]
                
                # –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª–∏–≥–æ–Ω—ã –∏–∑ –º–∞—Å–∫–∏
                mask_path = masks_path / filename
                polygons = mask_to_polygons(mask_path, instance_id, category_id)
                
                # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –ø–æ–ª–∏–≥–æ–Ω –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—É—é —Å—Ç—Ä–æ–∫—É
                for polygon in polygons:
                    # –§–æ—Ä–º–∞—Ç YOLO: class_id x1 y1 x2 y2 ... xn yn
                    line = f"{yolo_class} " + " ".join([f"{coord:.6f}" for coord in polygon])
                    f.write(line + "\n")
    
    print(f"\n‚úÖ Conversion complete!")
    print(f"   Images: {yolo_images_dir}")
    print(f"   Labels: {yolo_labels_dir}")
    print(f"   Config: {yaml_path}")
    print(f"\nüìù Next steps:")
    print(f"   1. Train: yolo segment train data={yaml_path} model=yolo11l-seg.pt epochs=50")
    print(f"   2. Validate: yolo segment val data={yaml_path} model=runs/segment/train/weights/best.pt")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Convert COCO Instance Segmentation to YOLO format")
    parser.add_argument('dataset_path', type=str, help='Path to COCO dataset folder')
    parser.add_argument('--output', type=str, default=None, help='Output path for YOLO dataset')
    
    args = parser.parse_args()
    
    convert_coco_to_yolo(args.dataset_path, args.output)
