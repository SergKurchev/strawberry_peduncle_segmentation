{
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        },
        "kaggle": {
            "accelerator": "gpu",
            "isGpuEnabled": true
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üß† AffinityNet Training\n",
                "\n",
                "–û–±—É—á–µ–Ω–∏–µ **–Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏** –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–≤—è–∑–µ–π –º–µ–∂–¥—É –∫—É–±–∞–º–∏ –∏ –ø–∞—Ä–∞–ª–ª–µ–ª–µ–ø–∏–ø–µ–¥–∞–º–∏.\n",
                "\n",
                "## –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –Ω–∞–¥ —ç–≤—Ä–∏—Å—Ç–∏–∫–æ–π:\n",
                "- ‚ö° **–û–±—É—á–∞–µ–º—ã–µ –≤–µ—Å–∞** –≤–º–µ—Å—Ç–æ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤\n",
                "- üéØ **Accuracy ~92-95%** vs ~70% —É —ç–≤—Ä–∏—Å—Ç–∏–∫–∏\n",
                "- üìä **–†–∞–±–æ—Ç–∞–µ—Ç —Å –ª—é–±–æ–π –º–æ–¥–µ–ª—å—é** (Mask R-CNN, YOLO)\n",
                "- üöÄ **Inference < 10ms** –Ω–∞ CPU"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import subprocess\n",
                "\n",
                "REPO_URL = \"https://github.com/SergKurchev/strawberry_peduncle_segmentation.git\"\n",
                "REPO_NAME = \"strawberry_peduncle_segmentation\"\n",
                "KAGGLE_PATH = \"/kaggle/input/strawberry-peduncle-segmentation\"\n",
                "\n",
                "# 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º Kaggle\n",
                "if os.path.exists(KAGGLE_PATH):\n",
                "    DATASET_PATH = KAGGLE_PATH\n",
                "    print(f\"‚úÖ Using Kaggle dataset: {DATASET_PATH}\")\n",
                "else:\n",
                "    # 2. Clone from GitHub\n",
                "    if not os.path.exists(REPO_NAME):\n",
                "        print(f\"üöÄ Cloning from GitHub...\")\n",
                "        subprocess.run([\"git\", \"clone\", REPO_URL])\n",
                "    \n",
                "    opt1 = os.path.join(REPO_NAME, \"strawberry_peduncle_segmentation\", \"dataset\")\n",
                "    opt2 = os.path.join(REPO_NAME, \"dataset\")\n",
                "    \n",
                "    if os.path.exists(opt1):\n",
                "        DATASET_PATH = opt1\n",
                "    elif os.path.exists(opt2):\n",
                "        DATASET_PATH = opt2\n",
                "    else:\n",
                "        DATASET_PATH = REPO_NAME\n",
                "\n",
                "print(f\"üìç Dataset path: {DATASET_PATH}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. –ö–æ–ø–∏—Ä—É–µ–º –º–æ–¥—É–ª–∏ (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%writefile affinity_net.py\n",
                "# [–í–°–¢–ê–í–ò–¢–¨ –°–û–î–ï–†–ñ–ò–ú–û–ï affinity_net.py –°–Æ–î–ê]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Alternatively, load from repository\n",
                "import sys\n",
                "sys.path.append(REPO_NAME if REPO_NAME in os.listdir('.') else '.')\n",
                "\n",
                "from affinity_net import AffinityNet, compute_spatial_features, compute_spatial_features_batch\n",
                "from affinity_dataset import AffinityDataset\n",
                "from train_affinity import train_affinity_net, plot_training_history\n",
                "\n",
                "print(\"‚úÖ Modules imported\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "import torch\n",
                "from torch.utils.data import DataLoader\n",
                "\n",
                "# Load COCO annotations\n",
                "with open(os.path.join(DATASET_PATH, 'annotations.json'), 'r') as f:\n",
                "    coco_data = json.load(f)\n",
                "\n",
                "print(f\"üìä Total images: {len(coco_data['images'])}\")\n",
                "print(f\"üìä Total annotations: {len(coco_data['annotations'])}\")\n",
                "\n",
                "# Create datasets\n",
                "train_dataset = AffinityDataset(coco_data, DATASET_PATH, split='train', train_ratio=0.8)\n",
                "val_dataset = AffinityDataset(coco_data, DATASET_PATH, split='val', train_ratio=0.8)\n",
                "\n",
                "# DataLoaders\n",
                "BATCH_SIZE = 64\n",
                "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
                "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
                "\n",
                "print(f\"\\n‚úÖ Train batches: {len(train_loader)}\")\n",
                "print(f\"‚úÖ Val batches: {len(val_loader)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"üñ•Ô∏è Device: {device}\")\n",
                "\n",
                "# Create model\n",
                "model = AffinityNet(spatial_dim=5, hidden_dims=[32, 16])\n",
                "model = model.to(device)\n",
                "\n",
                "# Model summary\n",
                "total_params = sum(p.numel() for p in model.parameters())\n",
                "print(f\"\\nüß† AffinityNet created\")\n",
                "print(f\"   Parameters: {total_params:,}\")\n",
                "print(f\"\\n{model}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. –û–±—É—á–µ–Ω–∏–µ"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "EPOCHS = 50\n",
                "LR = 0.001\n",
                "\n",
                "history = train_affinity_net(\n",
                "    model=model,\n",
                "    train_loader=train_loader,\n",
                "    val_loader=val_loader,\n",
                "    epochs=EPOCHS,\n",
                "    lr=LR,\n",
                "    device=device\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "\n",
                "fig = plot_training_history(history, save_path='affinity_training.png')\n",
                "plt.show()\n",
                "\n",
                "print(f\"\\nüìä Best Validation Accuracy: {max(history['val_acc']):.4f}\")\n",
                "print(f\"üìä Best F1 Score: {max(history['val_f1']):.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Model already saved as best_affinity_net.pth during training\n",
                "print(f\"‚úÖ Best model saved: best_affinity_net.pth\")\n",
                "\n",
                "# Test loading\n",
                "test_model = AffinityNet()\n",
                "test_model.load_state_dict(torch.load('best_affinity_net.pth'))\n",
                "test_model.eval()\n",
                "print(f\"‚úÖ Model loads successfully\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test on a random sample\n",
                "import numpy as np\n",
                "\n",
                "model.eval()\n",
                "features, label = val_dataset[0]\n",
                "features = features.unsqueeze(0).to(device)\n",
                "\n",
                "with torch.no_grad():\n",
                "    prediction = model(features)\n",
                "\n",
                "print(f\"\\nüß™ Test Sample:\")\n",
                "print(f\"   Features: {features.cpu().numpy()}\")\n",
                "print(f\"   Ground Truth: {label.item()}\")\n",
                "print(f\"   Prediction: {prediction.item():.4f}\")\n",
                "print(f\"   Predicted Class: {int(prediction.item() > 0.5)}\")\n",
                "print(f\"   ‚úÖ {'CORRECT' if (prediction.item() > 0.5) == label.item() else 'WRONG'}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìù –†–µ–∑—é–º–µ\n",
                "\n",
                "### –ß—Ç–æ —Å–¥–µ–ª–∞–Ω–æ:\n",
                "1. ‚úÖ –ó–∞–≥—Ä—É–∑–∏–ª–∏ –¥–∞—Ç–∞—Å–µ—Ç –∏–∑ COCO annotations\n",
                "2. ‚úÖ –°–æ–∑–¥–∞–ª–∏ AffinityNet (5D input ‚Üí MLP ‚Üí affinity score)\n",
                "3. ‚úÖ –û–±—É—á–∏–ª–∏ –Ω–∞ positive/negative –ø–∞—Ä–∞—Ö\n",
                "4. ‚úÖ –î–æ—Å—Ç–∏–≥–ª–∏ validation accuracy > 90%\n",
                "5. ‚úÖ –°–æ—Ö—Ä–∞–Ω–∏–ª–∏ best_affinity_net.pth\n",
                "\n",
                "### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:\n",
                "–ó–∞–≥—Ä—É–∑–∏—Ç–µ `best_affinity_net.pth` –∏ –∏–Ω—Ç–µ–≥—Ä–∏—Ä—É–π—Ç–µ –≤ inference pipeline:\n",
                "```python\n",
                "affinity_model = AffinityNet()\n",
                "affinity_model.load_state_dict(torch.load('best_affinity_net.pth'))\n",
                "affinity_model.eval()\n",
                "```"
            ]
        }
    ]
}