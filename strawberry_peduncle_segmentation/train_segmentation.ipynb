{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "isGpuEnabled": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –∫—É–±–æ–≤ –∏ –ø–∞—Ä–∞–ª–ª–µ–ª–µ–ø–∏–ø–µ–¥–æ–≤ —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º —Å–≤—è–∑–µ–π\n",
        "\n",
        "–≠—Ç–æ—Ç –Ω–æ—É—Ç–±—É–∫ –æ–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å Mask R-CNN –¥–ª—è:\n",
        "1. **Instance Segmentation** –∫—Ä–∞—Å–Ω—ã—Ö –∫—É–±–æ–≤ –∏ –∑–µ–ª—ë–Ω—ã—Ö –ø–∞—Ä–∞–ª–ª–µ–ª–µ–ø–∏–ø–µ–¥–æ–≤\n",
        "2. **–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–≤—è–∑–µ–π** –∫–∞–∫–æ–π –ø–∞—Ä–∞–ª–ª–µ–ª–µ–ø–∏–ø–µ–¥ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∏—Ç –∫–∞–∫–æ–º—É –∫—É–±—É\n",
        "\n",
        "–î–∞—Ç–∞—Å–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ COCO —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º –ø–æ–ª–µ–º `parent_id`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install torch torchvision\n",
        "!pip install pycocotools\n",
        "!pip install opencv-python-headless\n",
        "!pip install albumentations\n",
        "!pip install matplotlib\n",
        "!pip install scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "import torchvision.transforms as T\n",
        "\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- –õ–û–ì–ò–ö–ê –ó–ê–ì–†–£–ó–ö–ò –î–ê–¢–ê–°–ï–¢–ê ---\n",
        "import os\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "REPO_URL = \"https://github.com/SergKurchev/strawberry_peduncle_segmentation.git\"\n",
        "REPO_NAME = \"strawberry_peduncle_segmentation\"\n",
        "KAGGLE_PATH = \"/kaggle/input/strawberry-peduncle-segmentation\"\n",
        "\n",
        "# 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–∞ Kaggle (–µ—Å–ª–∏ –∑–∞–ø—É—Å–∫ —Ç–∞–º)\n",
        "if os.path.exists(KAGGLE_PATH):\n",
        "    DATASET_PATH = KAGGLE_PATH\n",
        "    print(f\"‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–∞—Ç–∞—Å–µ—Ç –∏–∑ Kaggle Input: {DATASET_PATH}\")\n",
        "else:\n",
        "    # 2. –ï—Å–ª–∏ –Ω–∞ Kaggle –Ω–µ—Ç, –∫–ª–æ–Ω–∏—Ä—É–µ–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –∏–∑ GitHub\n",
        "    if not os.path.exists(REPO_NAME):\n",
        "        print(f\"üöÄ –ö–ª–æ–Ω–∏—Ä—É–µ–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –∏–∑ GitHub: {REPO_URL}...\")\n",
        "        subprocess.run([\"git\", \"clone\", REPO_URL])\n",
        "    else:\n",
        "        print(f\"‚úÖ –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π {REPO_NAME} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.\")\n",
        "    \n",
        "    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—É—Ç–∏ –∫ –¥–∞—Ç–∞—Å–µ—Ç—É –≤–Ω—É—Ç—Ä–∏ —Ä–µ–ø–æ\n",
        "    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–≤–∞ –≤–∞—Ä–∏–∞–Ω—Ç–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã (—Å –≤–ª–æ–∂–µ–Ω–Ω–æ–π –ø–∞–ø–∫–æ–π –∏ –±–µ–∑)\n",
        "    opt1 = os.path.join(REPO_NAME, \"strawberry_peduncle_segmentation\", \"dataset\")\n",
        "    opt2 = os.path.join(REPO_NAME, \"dataset\")\n",
        "    \n",
        "    if os.path.exists(opt1):\n",
        "        DATASET_PATH = opt1\n",
        "    elif os.path.exists(opt2):\n",
        "        DATASET_PATH = opt2\n",
        "    else:\n",
        "        DATASET_PATH = REPO_NAME\n",
        "        print(f\"‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ: –ü–∞–ø–∫–∞ 'dataset' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ—Ä–µ–Ω—å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è.\")\n",
        "\n",
        "print(f\"üìç –ò—Ç–æ–≥–æ–≤—ã–π –ø—É—Ç—å –∫ –¥–∞—Ç–∞—Å–µ—Ç—É: {DATASET_PATH}\")\n",
        "\n",
        "IMAGES_PATH = os.path.join(DATASET_PATH, \"images\")\n",
        "MASKS_PATH = os.path.join(DATASET_PATH, \"masks\")\n",
        "ANNOTATIONS_PATH = os.path.join(DATASET_PATH, \"annotations.json\")\n",
        "\n",
        "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n",
        "if not os.path.exists(IMAGES_PATH):\n",
        "    print(f\"‚ùå –í–ù–ò–ú–ê–ù–ò–ï: –ü–∞–ø–∫–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –ø–æ –ø—É—Ç–∏: {IMAGES_PATH}\")\n",
        "    print(f\"   –ï—Å–ª–∏ –≤—ã –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ GitHub, —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–æ–±–∞–≤–ª–µ–Ω—ã –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π.\")\n",
        "    print(f\"   –ï—Å–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ Kaggle, –¥–æ–±–∞–≤—å—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç –≤ Input.\")\n",
        "\n",
        "# –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
        "NUM_CLASSES = 3  # background + red_cube + green_parallelepiped\n",
        "BATCH_SIZE = 4\n",
        "NUM_EPOCHS = 30\n",
        "LEARNING_RATE = 0.005\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# –ö–∞—Ç–µ–≥–æ—Ä–∏–∏\n",
        "CATEGORIES = {\n",
        "    0: \"background\",\n",
        "    1: \"red_cube\",\n",
        "    2: \"green_parallelepiped\"\n",
        "}\n",
        "\n",
        "# –†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏\n",
        "TRAIN_RATIO = 0.8\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Dataset –∫–ª–∞—Å—Å"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CubeParallelepipedDataset(Dataset):\n",
        "    \"\"\"Dataset –¥–ª—è –∫—É–±–æ–≤ –∏ –ø–∞—Ä–∞–ª–ª–µ–ª–µ–ø–∏–ø–µ–¥–æ–≤ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å–≤—è–∑—è—Ö.\"\"\"\n",
        "    \n",
        "    def __init__(self, images_path, masks_path, annotations_path, transforms=None):\n",
        "        self.images_path = images_path\n",
        "        self.masks_path = masks_path\n",
        "        self.transforms = transforms\n",
        "        \n",
        "        # –ó–∞–≥—Ä—É–∑–∫–∞ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π\n",
        "        with open(annotations_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "        \n",
        "        self.images_info = {img['id']: img for img in data['images']}\n",
        "        \n",
        "        # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º\n",
        "        self.annotations_by_image = defaultdict(list)\n",
        "        for ann in data['annotations']:\n",
        "            self.annotations_by_image[ann['image_id']].append(ann)\n",
        "        \n",
        "        self.image_ids = list(self.images_info.keys())\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.image_ids)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        image_id = self.image_ids[idx]\n",
        "        image_info = self.images_info[image_id]\n",
        "        \n",
        "        # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
        "        img_path = os.path.join(self.images_path, image_info['file_name'])\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        image = np.array(image)\n",
        "        \n",
        "        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–∞—Å–∫–∏\n",
        "        mask_path = os.path.join(self.masks_path, image_info['file_name'])\n",
        "        mask_image = np.array(Image.open(mask_path).convert(\"RGB\"))\n",
        "        \n",
        "        # –ü–æ–ª—É—á–µ–Ω–∏–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π –¥–ª—è —ç—Ç–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
        "        annotations = self.annotations_by_image[image_id]\n",
        "        \n",
        "        boxes = []\n",
        "        labels = []\n",
        "        masks = []\n",
        "        instance_ids = []\n",
        "        parent_ids = []\n",
        "        \n",
        "        for ann in annotations:\n",
        "            # Bbox –≤ —Ñ–æ—Ä–º–∞—Ç–µ [x, y, width, height] -> [x1, y1, x2, y2]\n",
        "            x, y, w, h = ann['bbox']\n",
        "            boxes.append([x, y, x + w, y + h])\n",
        "            labels.append(ann['category_id'])\n",
        "            instance_ids.append(ann['instance_id'])\n",
        "            parent_ids.append(ann['parent_id'])\n",
        "            \n",
        "            # –°–æ–∑–¥–∞–Ω–∏–µ –±–∏–Ω–∞—Ä–Ω–æ–π –º–∞—Å–∫–∏ –∏–∑ —Ü–≤–µ—Ç–æ–≤–æ–π –º–∞—Å–∫–∏\n",
        "            seg_color = ann['segmentation_color']\n",
        "            obj_mask = np.all(mask_image == seg_color, axis=2).astype(np.uint8)\n",
        "            masks.append(obj_mask)\n",
        "        \n",
        "        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Ç–µ–Ω–∑–æ—Ä—ã\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32) if boxes else torch.zeros((0, 4), dtype=torch.float32)\n",
        "        labels = torch.as_tensor(labels, dtype=torch.int64) if labels else torch.zeros((0,), dtype=torch.int64)\n",
        "        masks = torch.as_tensor(np.array(masks), dtype=torch.uint8) if masks else torch.zeros((0, image.shape[0], image.shape[1]), dtype=torch.uint8)\n",
        "        instance_ids = torch.as_tensor(instance_ids, dtype=torch.int64) if instance_ids else torch.zeros((0,), dtype=torch.int64)\n",
        "        parent_ids = torch.as_tensor(parent_ids, dtype=torch.int64) if parent_ids else torch.zeros((0,), dtype=torch.int64)\n",
        "        \n",
        "        image_id_tensor = torch.tensor([image_id])\n",
        "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0]) if len(boxes) > 0 else torch.zeros((0,))\n",
        "        iscrowd = torch.zeros((len(labels),), dtype=torch.int64)\n",
        "        \n",
        "        target = {\n",
        "            \"boxes\": boxes,\n",
        "            \"labels\": labels,\n",
        "            \"masks\": masks,\n",
        "            \"image_id\": image_id_tensor,\n",
        "            \"area\": area,\n",
        "            \"iscrowd\": iscrowd,\n",
        "            \"instance_ids\": instance_ids,\n",
        "            \"parent_ids\": parent_ids\n",
        "        }\n",
        "        \n",
        "        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ —Ç–µ–Ω–∑–æ—Ä\n",
        "        image = torch.as_tensor(image, dtype=torch.float32).permute(2, 0, 1) / 255.0\n",
        "        \n",
        "        if self.transforms:\n",
        "            image, target = self.transforms(image, target)\n",
        "        \n",
        "        return image, target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. –ú–æ–¥–µ–ª—å Mask R-CNN —Å –≥–æ–ª–æ–≤–æ–π –¥–ª—è —Å–≤—è–∑–µ–π"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AssociationHead(nn.Module):\n",
        "    \"\"\"–ì–æ–ª–æ–≤–∞ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–≤—è–∑–µ–π –º–µ–∂–¥—É –æ–±—ä–µ–∫—Ç–∞–º–∏.\n",
        "    \n",
        "    –î–ª—è –∫–∞–∂–¥–æ–π –ø–∞—Ä—ã (–ø–∞—Ä–∞–ª–ª–µ–ª–µ–ø–∏–ø–µ–¥, –∫—É–±) –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å–≤—è–∑–∏.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, feature_dim=256):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.feature_dim = feature_dim\n",
        "        \n",
        "        # MLP –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–∞—Ä—ã –æ–±—ä–µ–∫—Ç–æ–≤\n",
        "        self.pair_mlp = nn.Sequential(\n",
        "            nn.Linear(feature_dim * 2 + 4, 256),  # +4 –¥–ª—è –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã—Ö –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "    \n",
        "    def forward(self, cube_features, para_features, cube_boxes, para_boxes):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            cube_features: (N_cubes, feature_dim) - –ø—Ä–∏–∑–Ω–∞–∫–∏ –∫—É–±–æ–≤\n",
        "            para_features: (N_paras, feature_dim) - –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø–∞—Ä–∞–ª–ª–µ–ª–µ–ø–∏–ø–µ–¥–æ–≤\n",
        "            cube_boxes: (N_cubes, 4) - bbox –∫—É–±–æ–≤\n",
        "            para_boxes: (N_paras, 4) - bbox –ø–∞—Ä–∞–ª–ª–µ–ª–µ–ø–∏–ø–µ–¥–æ–≤\n",
        "            \n",
        "        Returns:\n",
        "            association_scores: (N_paras, N_cubes) - –º–∞—Ç—Ä–∏—Ü–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π —Å–≤—è–∑–µ–π\n",
        "        \"\"\"\n",
        "        n_cubes = cube_features.shape[0]\n",
        "        n_paras = para_features.shape[0]\n",
        "        \n",
        "        if n_cubes == 0 or n_paras == 0:\n",
        "            return torch.zeros(n_paras, n_cubes, device=cube_features.device)\n",
        "        \n",
        "        # –í—ã—á–∏—Å–ª—è–µ–º —Ü–µ–Ω—Ç—Ä—ã bbox\n",
        "        cube_centers = (cube_boxes[:, :2] + cube_boxes[:, 2:]) / 2\n",
        "        para_centers = (para_boxes[:, :2] + para_boxes[:, 2:]) / 2\n",
        "        \n",
        "        scores = torch.zeros(n_paras, n_cubes, device=cube_features.device)\n",
        "        \n",
        "        for i in range(n_paras):\n",
        "            for j in range(n_cubes):\n",
        "                # –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ)\n",
        "                rel_pos = para_centers[i] - cube_centers[j]\n",
        "                rel_size = (\n",
        "                    (para_boxes[i, 2:] - para_boxes[i, :2]) / \n",
        "                    (cube_boxes[j, 2:] - cube_boxes[j, :2] + 1e-6)\n",
        "                )\n",
        "                \n",
        "                # –ö–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
        "                pair_input = torch.cat([\n",
        "                    para_features[i],\n",
        "                    cube_features[j],\n",
        "                    rel_pos,\n",
        "                    rel_size\n",
        "                ])\n",
        "                \n",
        "                scores[i, j] = self.pair_mlp(pair_input)\n",
        "        \n",
        "        return torch.sigmoid(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_model(num_classes, pretrained=True):\n",
        "    \"\"\"–°–æ–∑–¥–∞—ë—Ç –º–æ–¥–µ–ª—å Mask R-CNN.\"\"\"\n",
        "    \n",
        "    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å\n",
        "    model = maskrcnn_resnet50_fpn(pretrained=pretrained)\n",
        "    \n",
        "    # –ó–∞–º–µ–Ω—è–µ–º –≥–æ–ª–æ–≤—É –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "    \n",
        "    # –ó–∞–º–µ–Ω—è–µ–º –≥–æ–ª–æ–≤—É –º–∞—Å–æ–∫\n",
        "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
        "    hidden_layer = 256\n",
        "    model.roi_heads.mask_predictor = MaskRCNNPredictor(\n",
        "        in_features_mask, hidden_layer, num_classes\n",
        "    )\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CubeParallelepipedModel(nn.Module):\n",
        "    \"\"\"–ü–æ–ª–Ω–∞—è –º–æ–¥–µ–ª—å: Mask R-CNN + Association Head.\"\"\"\n",
        "    \n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.detector = get_model(num_classes)\n",
        "        self.association_head = AssociationHead(feature_dim=1024)\n",
        "        \n",
        "        # –ü—Ä–æ–µ–∫—Ç–æ—Ä –¥–ª—è box features -> association features\n",
        "        self.feature_projector = nn.Sequential(\n",
        "            nn.Linear(1024, 256),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "    \n",
        "    def forward(self, images, targets=None):\n",
        "        \"\"\"\n",
        "        Training: returns losses dict\n",
        "        Inference: returns detections + associations\n",
        "        \"\"\"\n",
        "        if self.training and targets is not None:\n",
        "            # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π forward –¥–ª—è Mask R-CNN\n",
        "            losses = self.detector(images, targets)\n",
        "            \n",
        "            # TODO: –î–æ–±–∞–≤–∏—Ç—å association loss –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏\n",
        "            return losses\n",
        "        else:\n",
        "            # Inference\n",
        "            detections = self.detector(images)\n",
        "            return detections\n",
        "    \n",
        "    def predict_associations(self, detections):\n",
        "        \"\"\"–ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —Å–≤—è–∑–∏ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–π –ø–æ—Å–ª–µ inference.\n",
        "        \n",
        "        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –ø—Ä–æ—Å—Ç—É—é —ç–≤—Ä–∏—Å—Ç–∏–∫—É –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è,\n",
        "        —Ç–∞–∫ –∫–∞–∫ —É –Ω–∞—Å –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–º features –ø–æ—Å–ª–µ inference.\n",
        "        \"\"\"\n",
        "        results = []\n",
        "        \n",
        "        for det in detections:\n",
        "            labels = det['labels'].cpu().numpy()\n",
        "            boxes = det['boxes'].cpu().numpy()\n",
        "            scores = det['scores'].cpu().numpy()\n",
        "            masks = det['masks'].cpu().numpy()\n",
        "            \n",
        "            # –ò–Ω–¥–µ–∫—Å—ã –∫—É–±–æ–≤ –∏ –ø–∞—Ä–∞–ª–ª–µ–ª–µ–ø–∏–ø–µ–¥–æ–≤\n",
        "            cube_indices = np.where(labels == 1)[0]\n",
        "            para_indices = np.where(labels == 2)[0]\n",
        "            \n",
        "            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å–≤—è–∑–µ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è\n",
        "            associations = {}\n",
        "            \n",
        "            for para_idx in para_indices:\n",
        "                para_box = boxes[para_idx]\n",
        "                para_center = np.array([(para_box[0] + para_box[2]) / 2, \n",
        "                                        (para_box[1] + para_box[3]) / 2])\n",
        "                \n",
        "                min_dist = float('inf')\n",
        "                best_cube_idx = -1\n",
        "                \n",
        "                for cube_idx in cube_indices:\n",
        "                    cube_box = boxes[cube_idx]\n",
        "                    cube_center = np.array([(cube_box[0] + cube_box[2]) / 2,\n",
        "                                           (cube_box[1] + cube_box[3]) / 2])\n",
        "                    \n",
        "                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–∞—Ä–∞–ª–ª–µ–ª–µ–ø–∏–ø–µ–¥ –≤—ã—à–µ –∫—É–±–∞ (–º–µ–Ω—å—à–µ y = –≤—ã—à–µ)\n",
        "                    if para_center[1] < cube_center[1]:\n",
        "                        dist = np.linalg.norm(para_center - cube_center)\n",
        "                        if dist < min_dist:\n",
        "                            min_dist = dist\n",
        "                            best_cube_idx = cube_idx\n",
        "                \n",
        "                associations[int(para_idx)] = int(best_cube_idx) if best_cube_idx >= 0 else None\n",
        "            \n",
        "            results.append({\n",
        "                'labels': labels,\n",
        "                'boxes': boxes,\n",
        "                'scores': scores,\n",
        "                'masks': masks,\n",
        "                'associations': associations\n",
        "            })\n",
        "        \n",
        "        return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. –§—É–Ω–∫—Ü–∏–∏ –æ–±—É—á–µ–Ω–∏—è"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    \"\"\"–ö–∞—Å—Ç–æ–º–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è DataLoader.\"\"\"\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "\n",
        "def train_one_epoch(model, optimizer, data_loader, device, epoch):\n",
        "    \"\"\"–û–±—É—á–µ–Ω–∏–µ –æ–¥–Ω–æ–π —ç–ø–æ—Ö–∏.\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    \n",
        "    for batch_idx, (images, targets) in enumerate(data_loader):\n",
        "        images = list(img.to(device) for img in images)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "        \n",
        "        loss_dict = model(images, targets)\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        total_loss += losses.item()\n",
        "        \n",
        "        if batch_idx % 10 == 0:\n",
        "            print(f\"Epoch [{epoch}] Batch [{batch_idx}/{len(data_loader)}] \"\n",
        "                  f\"Loss: {losses.item():.4f}\")\n",
        "    \n",
        "    return total_loss / len(data_loader)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, data_loader, device):\n",
        "    \"\"\"–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏.\"\"\"\n",
        "    model.eval()\n",
        "    \n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "    \n",
        "    for images, targets in data_loader:\n",
        "        images = list(img.to(device) for img in images)\n",
        "        \n",
        "        outputs = model(images)\n",
        "        \n",
        "        all_predictions.extend(outputs)\n",
        "        all_targets.extend(targets)\n",
        "    \n",
        "    return all_predictions, all_targets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–≤—è–∑–µ–π"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_association_accuracy(predictions, targets, iou_threshold=0.5):\n",
        "    \"\"\"–í—ã—á–∏—Å–ª—è–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–≤—è–∑–µ–π.\n",
        "    \n",
        "    –î–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω–æ–≥–æ –ø–∞—Ä–∞–ª–ª–µ–ª–µ–ø–∏–ø–µ–¥–∞ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç,\n",
        "    –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω —Å–≤—è–∑–∞–Ω–Ω—ã–π –∫—É–±.\n",
        "    \"\"\"\n",
        "    correct_associations = 0\n",
        "    total_associations = 0\n",
        "    \n",
        "    for pred, target in zip(predictions, targets):\n",
        "        pred_labels = pred['labels'].cpu().numpy()\n",
        "        pred_boxes = pred['boxes'].cpu().numpy()\n",
        "        \n",
        "        target_labels = target['labels'].cpu().numpy()\n",
        "        target_boxes = target['boxes'].cpu().numpy()\n",
        "        target_instance_ids = target['instance_ids'].cpu().numpy()\n",
        "        target_parent_ids = target['parent_ids'].cpu().numpy()\n",
        "        \n",
        "        # –ù–∞—Ö–æ–¥–∏–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –º–µ–∂–¥—É –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏ –∏ GT –ø–æ IoU\n",
        "        pred_para_indices = np.where(pred_labels == 2)[0]\n",
        "        target_para_indices = np.where(target_labels == 2)[0]\n",
        "        \n",
        "        for pred_idx in pred_para_indices:\n",
        "            pred_box = pred_boxes[pred_idx]\n",
        "            \n",
        "            # –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à–µ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –≤ GT\n",
        "            best_iou = 0\n",
        "            best_target_idx = -1\n",
        "            \n",
        "            for target_idx in target_para_indices:\n",
        "                target_box = target_boxes[target_idx]\n",
        "                iou = compute_iou(pred_box, target_box)\n",
        "                if iou > best_iou:\n",
        "                    best_iou = iou\n",
        "                    best_target_idx = target_idx\n",
        "            \n",
        "            if best_iou >= iou_threshold and best_target_idx >= 0:\n",
        "                total_associations += 1\n",
        "                \n",
        "                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å —Å–≤—è–∑–∏\n",
        "                # GT parent_id –¥–ª—è —ç—Ç–æ–≥–æ –ø–∞—Ä–∞–ª–ª–µ–ª–µ–ø–∏–ø–µ–¥–∞\n",
        "                gt_parent = target_parent_ids[best_target_idx]\n",
        "                \n",
        "                # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è —Å–≤—è–∑—å (–ø–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—é)\n",
        "                pred_associations = predict_associations_simple(pred_boxes, pred_labels)\n",
        "                pred_parent_idx = pred_associations.get(pred_idx, None)\n",
        "                \n",
        "                if pred_parent_idx is not None:\n",
        "                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–≤–ø–∞–¥–∞–µ—Ç –ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫—É–± —Å GT\n",
        "                    pred_cube_box = pred_boxes[pred_parent_idx]\n",
        "                    \n",
        "                    # –ù–∞—Ö–æ–¥–∏–º GT –∫—É–± —Å —ç—Ç–∏–º parent_id\n",
        "                    gt_cube_indices = np.where(\n",
        "                        (target_labels == 1) & (target_instance_ids == gt_parent)\n",
        "                    )[0]\n",
        "                    \n",
        "                    if len(gt_cube_indices) > 0:\n",
        "                        gt_cube_box = target_boxes[gt_cube_indices[0]]\n",
        "                        cube_iou = compute_iou(pred_cube_box, gt_cube_box)\n",
        "                        \n",
        "                        if cube_iou >= iou_threshold:\n",
        "                            correct_associations += 1\n",
        "    \n",
        "    accuracy = correct_associations / total_associations if total_associations > 0 else 0\n",
        "    return accuracy, correct_associations, total_associations\n",
        "\n",
        "\n",
        "def compute_iou(box1, box2):\n",
        "    \"\"\"–í—ã—á–∏—Å–ª—è–µ—Ç IoU –º–µ–∂–¥—É –¥–≤—É–º—è bbox.\"\"\"\n",
        "    x1 = max(box1[0], box2[0])\n",
        "    y1 = max(box1[1], box2[1])\n",
        "    x2 = min(box1[2], box2[2])\n",
        "    y2 = min(box1[3], box2[3])\n",
        "    \n",
        "    inter_area = max(0, x2 - x1) * max(0, y2 - y1)\n",
        "    \n",
        "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
        "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
        "    \n",
        "    union_area = box1_area + box2_area - inter_area\n",
        "    \n",
        "    return inter_area / union_area if union_area > 0 else 0\n",
        "\n",
        "\n",
        "def predict_associations_simple(boxes, labels):\n",
        "    \"\"\"–ü—Ä–æ—Å—Ç–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å–≤—è–∑–µ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è.\"\"\"\n",
        "    cube_indices = np.where(labels == 1)[0]\n",
        "    para_indices = np.where(labels == 2)[0]\n",
        "    \n",
        "    associations = {}\n",
        "    \n",
        "    for para_idx in para_indices:\n",
        "        para_box = boxes[para_idx]\n",
        "        para_center = np.array([(para_box[0] + para_box[2]) / 2,\n",
        "                                (para_box[1] + para_box[3]) / 2])\n",
        "        \n",
        "        min_dist = float('inf')\n",
        "        best_cube_idx = None\n",
        "        \n",
        "        for cube_idx in cube_indices:\n",
        "            cube_box = boxes[cube_idx]\n",
        "            cube_center = np.array([(cube_box[0] + cube_box[2]) / 2,\n",
        "                                   (cube_box[1] + cube_box[3]) / 2])\n",
        "            \n",
        "            # –ü–∞—Ä–∞–ª–ª–µ–ª–µ–ø–∏–ø–µ–¥ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–∞–¥ –∫—É–±–æ–º\n",
        "            if para_box[3] <= cube_box[1]:  # para bottom <= cube top\n",
        "                dist = np.linalg.norm(para_center - cube_center)\n",
        "                if dist < min_dist:\n",
        "                    min_dist = dist\n",
        "                    best_cube_idx = cube_idx\n",
        "        \n",
        "        associations[para_idx] = best_cube_idx\n",
        "    \n",
        "    return associations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤\n",
        "dataset = CubeParallelepipedDataset(\n",
        "    images_path=IMAGES_PATH,\n",
        "    masks_path=MASKS_PATH,\n",
        "    annotations_path=ANNOTATIONS_PATH\n",
        ")\n",
        "\n",
        "# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/val\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print(f\"Training samples: {len(train_dataset)}\")\n",
        "print(f\"Validation samples: {len(val_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –°–æ–∑–¥–∞–Ω–∏–µ DataLoader\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_fn,\n",
        "    num_workers=2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
        "model = get_model(NUM_CLASSES, pretrained=True)\n",
        "model.to(DEVICE)\n",
        "\n",
        "# –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = optim.SGD(params, lr=LEARNING_RATE, momentum=0.9, weight_decay=0.0005)\n",
        "\n",
        "# Learning rate scheduler\n",
        "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "\n",
        "print(f\"Model loaded on {DEVICE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –¶–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è\n",
        "train_losses = []\n",
        "best_loss = float('inf')\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS + 1):\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Epoch {epoch}/{NUM_EPOCHS}\")\n",
        "    print(f\"{'='*50}\")\n",
        "    \n",
        "    # –û–±—É—á–µ–Ω–∏–µ\n",
        "    avg_loss = train_one_epoch(model, optimizer, train_loader, DEVICE, epoch)\n",
        "    train_losses.append(avg_loss)\n",
        "    \n",
        "    print(f\"\\nAverage training loss: {avg_loss:.4f}\")\n",
        "    \n",
        "    # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ learning rate\n",
        "    lr_scheduler.step()\n",
        "    \n",
        "    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏\n",
        "    if avg_loss < best_loss:\n",
        "        best_loss = avg_loss\n",
        "        torch.save(model.state_dict(), 'best_model.pth')\n",
        "        print(f\"Saved best model with loss: {best_loss:.4f}\")\n",
        "    \n",
        "    # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞\n",
        "    if epoch % 5 == 0:\n",
        "        predictions, targets = evaluate(model, val_loader, DEVICE)\n",
        "        acc, correct, total = compute_association_accuracy(predictions, targets)\n",
        "        print(f\"\\nAssociation accuracy: {acc:.4f} ({correct}/{total})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ì—Ä–∞—Ñ–∏–∫ –æ–±—É—á–µ–Ω–∏—è\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_losses, 'b-', label='Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Progress')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig('training_progress.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_predictions(image, prediction, score_threshold=0.5):\n",
        "    \"\"\"–í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ —Å —Å–≤—è–∑—è–º–∏.\"\"\"\n",
        "    \n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
        "    \n",
        "    # –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å bbox\n",
        "    img_np = image.cpu().numpy().transpose(1, 2, 0)\n",
        "    axes[0].imshow(img_np)\n",
        "    axes[0].set_title('Detections')\n",
        "    \n",
        "    labels = prediction['labels'].cpu().numpy()\n",
        "    boxes = prediction['boxes'].cpu().numpy()\n",
        "    scores = prediction['scores'].cpu().numpy()\n",
        "    masks = prediction['masks'].cpu().numpy()\n",
        "    \n",
        "    colors = {1: 'red', 2: 'green'}\n",
        "    \n",
        "    # –†–∏—Å—É–µ–º bbox\n",
        "    for i in range(len(labels)):\n",
        "        if scores[i] >= score_threshold:\n",
        "            box = boxes[i]\n",
        "            label = labels[i]\n",
        "            color = colors.get(label, 'blue')\n",
        "            \n",
        "            rect = plt.Rectangle(\n",
        "                (box[0], box[1]), box[2] - box[0], box[3] - box[1],\n",
        "                fill=False, edgecolor=color, linewidth=2\n",
        "            )\n",
        "            axes[0].add_patch(rect)\n",
        "            axes[0].text(box[0], box[1] - 5, \n",
        "                        f\"{CATEGORIES[label]}: {scores[i]:.2f}\",\n",
        "                        color=color, fontsize=8)\n",
        "    \n",
        "    # –ú–∞—Å–∫–∏ —Å —Å–≤—è–∑—è–º–∏\n",
        "    combined_mask = np.zeros((*img_np.shape[:2], 3))\n",
        "    \n",
        "    # –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º —Å–≤—è–∑–∏\n",
        "    associations = predict_associations_simple(boxes, labels)\n",
        "    \n",
        "    for i in range(len(labels)):\n",
        "        if scores[i] >= score_threshold:\n",
        "            mask = masks[i, 0] > 0.5\n",
        "            label = labels[i]\n",
        "            \n",
        "            if label == 1:  # –ö—É–± - –∫—Ä–∞—Å–Ω—ã–π\n",
        "                combined_mask[mask] = [1, 0, 0]\n",
        "            elif label == 2:  # –ü–∞—Ä–∞–ª–ª–µ–ª–µ–ø–∏–ø–µ–¥ - –∑–µ–ª—ë–Ω—ã–π\n",
        "                combined_mask[mask] = [0, 1, 0]\n",
        "    \n",
        "    axes[1].imshow(img_np)\n",
        "    axes[1].imshow(combined_mask, alpha=0.5)\n",
        "    axes[1].set_title('Masks with Associations')\n",
        "    \n",
        "    # –†–∏—Å—É–µ–º –ª–∏–Ω–∏–∏ —Å–≤—è–∑–µ–π\n",
        "    for para_idx, cube_idx in associations.items():\n",
        "        if scores[para_idx] >= score_threshold and cube_idx is not None and scores[cube_idx] >= score_threshold:\n",
        "            para_box = boxes[para_idx]\n",
        "            cube_box = boxes[cube_idx]\n",
        "            \n",
        "            para_center = [(para_box[0] + para_box[2]) / 2, (para_box[1] + para_box[3]) / 2]\n",
        "            cube_center = [(cube_box[0] + cube_box[2]) / 2, (cube_box[1] + cube_box[3]) / 2]\n",
        "            \n",
        "            axes[1].plot([para_center[0], cube_center[0]], \n",
        "                        [para_center[1], cube_center[1]], \n",
        "                        'y-', linewidth=2)\n",
        "            axes[1].plot(*para_center, 'yo', markersize=8)\n",
        "            axes[1].plot(*cube_center, 'yo', markersize=8)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    return associations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ó–∞–≥—Ä—É–∑–∫–∞ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
        "model.load_state_dict(torch.load('best_model.pth'))\n",
        "model.eval()\n",
        "\n",
        "# –ü–æ–ª—É—á–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –∏–∑ validation set\n",
        "sample_images = []\n",
        "sample_targets = []\n",
        "\n",
        "for i in range(min(5, len(val_dataset))):\n",
        "    img, target = val_dataset[i]\n",
        "    sample_images.append(img)\n",
        "    sample_targets.append(target)\n",
        "\n",
        "# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
        "with torch.no_grad():\n",
        "    images_tensor = [img.to(DEVICE) for img in sample_images]\n",
        "    predictions = model(images_tensor)\n",
        "\n",
        "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞\n",
        "for i, (img, pred) in enumerate(zip(sample_images, predictions)):\n",
        "    print(f\"\\n--- Sample {i + 1} ---\")\n",
        "    associations = visualize_predictions(img, pred)\n",
        "    print(f\"Predicted associations: {associations}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'epochs': NUM_EPOCHS,\n",
        "    'train_losses': train_losses,\n",
        "}, 'cube_parallelepiped_model.pth')\n",
        "\n",
        "print(\"Model saved to cube_parallelepiped_model.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Inference –Ω–∞ –Ω–æ–≤—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def inference(model, image_path, device, score_threshold=0.5):\n",
        "    \"\"\"–ó–∞–ø—É—Å–∫ inference –Ω–∞ –æ–¥–Ω–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏.\"\"\"\n",
        "    \n",
        "    # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    image_tensor = torch.as_tensor(np.array(image), dtype=torch.float32).permute(2, 0, 1) / 255.0\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        prediction = model([image_tensor.to(device)])[0]\n",
        "    \n",
        "    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ score\n",
        "    keep = prediction['scores'] >= score_threshold\n",
        "    filtered_pred = {\n",
        "        'boxes': prediction['boxes'][keep],\n",
        "        'labels': prediction['labels'][keep],\n",
        "        'scores': prediction['scores'][keep],\n",
        "        'masks': prediction['masks'][keep]\n",
        "    }\n",
        "    \n",
        "    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
        "    visualize_predictions(image_tensor, filtered_pred, score_threshold)\n",
        "    \n",
        "    return filtered_pred\n",
        "\n",
        "# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:\n",
        "# result = inference(model, 'path/to/new/image.png', DEVICE)"
      ]
    }
  ]
}