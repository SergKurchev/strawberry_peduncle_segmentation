#!/usr/bin/env python3
"""
Dataset Statistics Analyzer
–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç –∏ –≤—ã–≤–æ–¥–∏—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
"""

import json
import os
import sys
from pathlib import Path
from collections import defaultdict
import numpy as np
from PIL import Image

def load_annotations(json_path):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π –∏–∑ JSON —Ñ–∞–π–ª–∞"""
    with open(json_path, 'r', encoding='utf-8') as f:
        return json.load(f)

def analyze_dataset(dataset_path):
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞"""
    dataset_path = Path(dataset_path)
    annotations_path = dataset_path / "annotations.json"
    images_path = dataset_path / "images"
    masks_path = dataset_path / "masks"
    
    if not annotations_path.exists():
        print(f"‚ùå –§–∞–π–ª annotations.json –Ω–µ –Ω–∞–π–¥–µ–Ω: {annotations_path}")
        return
    
    data = load_annotations(annotations_path)
    
    print("=" * 60)
    print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –î–ê–¢–ê–°–ï–¢–ê")
    print("=" * 60)
    
    # === 1. –û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è ===
    images = data.get("images", [])
    annotations = data.get("annotations", [])
    categories = data.get("categories", [])
    
    print(f"\nüìÅ –ü—É—Ç—å: {dataset_path}")
    print(f"üñºÔ∏è  –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(images)}")
    print(f"üìù –ê–Ω–Ω–æ—Ç–∞—Ü–∏–π: {len(annotations)}")
    print(f"üè∑Ô∏è  –ö–∞—Ç–µ–≥–æ—Ä–∏–π: {len(categories)}")
    
    for cat in categories:
        print(f"   - {cat['id']}: {cat['name']}")
    
    # === 2. –†–∞–∑–º–µ—Ä—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π ===
    if images:
        sizes = set((img['width'], img['height']) for img in images)
        print(f"\nüìê –†–∞–∑–º–µ—Ä—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:")
        for w, h in sizes:
            count = sum(1 for img in images if img['width'] == w and img['height'] == h)
            print(f"   {w}x{h}: {count} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    
    # === 3. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º ===
    category_counts = defaultdict(int)
    category_names = {cat['id']: cat['name'] for cat in categories}
    
    for ann in annotations:
        category_counts[ann['category_id']] += 1
    
    print(f"\nüìä –û–±—ä–µ–∫—Ç–æ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
    for cat_id, count in sorted(category_counts.items()):
        name = category_names.get(cat_id, f"unknown_{cat_id}")
        print(f"   {name} (id={cat_id}): {count}")
    
    # === 4. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ bbox ===
    bbox_widths = []
    bbox_heights = []
    bbox_areas = []
    
    for ann in annotations:
        bbox = ann.get('bbox', [0, 0, 0, 0])
        if len(bbox) >= 4:
            bbox_widths.append(bbox[2])
            bbox_heights.append(bbox[3])
            bbox_areas.append(ann.get('area', bbox[2] * bbox[3]))
    
    if bbox_widths:
        print(f"\nüìè –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ Bounding Box:")
        print(f"   –®–∏—Ä–∏–Ω–∞:  min={min(bbox_widths):.1f}, max={max(bbox_widths):.1f}, avg={np.mean(bbox_widths):.1f}")
        print(f"   –í—ã—Å–æ—Ç–∞:  min={min(bbox_heights):.1f}, max={max(bbox_heights):.1f}, avg={np.mean(bbox_heights):.1f}")
        print(f"   –ü–ª–æ—â–∞–¥—å: min={min(bbox_areas):.1f}, max={max(bbox_areas):.1f}, avg={np.mean(bbox_areas):.1f}")
    
    # === 5. –ü—Ä–æ–≤–µ—Ä–∫–∞ parent_id —Å–≤—è–∑–µ–π ===
    cubes = [ann for ann in annotations if ann['category_id'] == 1]
    parallelepipeds = [ann for ann in annotations if ann['category_id'] == 2]
    
    print(f"\nüîó –°–≤—è–∑–∏ parent_id:")
    print(f"   –ö—É–±–æ–≤: {len(cubes)}")
    print(f"   –ü–∞—Ä–∞–ª–ª–µ–ª–µ–ø–∏–ø–µ–¥–æ–≤: {len(parallelepipeds)}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ parent_id
    orphaned = 0
    valid_links = 0
    cube_instance_ids = set(ann['instance_id'] for ann in cubes)
    
    for para in parallelepipeds:
        if para['parent_id'] in cube_instance_ids:
            valid_links += 1
        else:
            orphaned += 1
    
    print(f"   –ö–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö —Å–≤—è–∑–µ–π: {valid_links}")
    if orphaned > 0:
        print(f"   ‚ö†Ô∏è –°–∏—Ä–æ—Ç (–±–µ–∑ —Ä–æ–¥–∏—Ç–µ–ª—è): {orphaned}")
    
    # === 6. –û–±—ä–µ–∫—Ç–æ–≤ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ ===
    objects_per_image = defaultdict(int)
    for ann in annotations:
        objects_per_image[ann['image_id']] += 1
    
    if objects_per_image:
        counts = list(objects_per_image.values())
        print(f"\nüî¢ –û–±—ä–µ–∫—Ç–æ–≤ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ:")
        print(f"   min={min(counts)}, max={max(counts)}, avg={np.mean(counts):.1f}")
    
    # === 7. –ü—Ä–æ–≤–µ—Ä–∫–∞ segmentation_color ===
    colors = set()
    for ann in annotations:
        color = tuple(ann.get('segmentation_color', [0, 0, 0]))
        colors.add(color)
    
    print(f"\nüé® –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ü–≤–µ—Ç–æ–≤ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏: {len(colors)}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—ë—Ä–Ω—ã–π —Ü–≤–µ—Ç
    black_annotations = [ann for ann in annotations if ann.get('segmentation_color') == [0, 0, 0]]
    if black_annotations:
        print(f"   ‚ö†Ô∏è –ê–Ω–Ω–æ—Ç–∞—Ü–∏–π —Å —á—ë—Ä–Ω—ã–º —Ü–≤–µ—Ç–æ–º (0,0,0): {len(black_annotations)}")
    
    # === 8. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–æ–≤ ===
    print(f"\nüìÇ –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–æ–≤:")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    missing_images = 0
    if images_path.exists():
        for img in images:
            img_file = images_path / img['file_name']
            if not img_file.exists():
                missing_images += 1
        print(f"   –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {len(images) - missing_images}/{len(images)} —Å—É—â–µ—Å—Ç–≤—É—é—Ç")
        if missing_images > 0:
            print(f"   ‚ö†Ô∏è –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö: {missing_images}")
    else:
        print(f"   ‚ùå –ü–∞–ø–∫–∞ images –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∞—Å–∫–∏
    missing_masks = 0
    if masks_path.exists():
        for img in images:
            mask_file = masks_path / img['file_name']
            if not mask_file.exists():
                missing_masks += 1
        print(f"   –ú–∞—Å–∫–∏: {len(images) - missing_masks}/{len(images)} —Å—É—â–µ—Å—Ç–≤—É—é—Ç")
        if missing_masks > 0:
            print(f"   ‚ö†Ô∏è –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö: {missing_masks}")
    else:
        print(f"   ‚ùå –ü–∞–ø–∫–∞ masks –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
    
    # === 9. –ê–Ω–∞–ª–∏–∑ –º–∞—Å–æ–∫ (–µ—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É—é—Ç) ===
    if masks_path.exists():
        print(f"\nüé≠ –ê–Ω–∞–ª–∏–∑ –º–∞—Å–æ–∫:")
        black_masks = 0
        non_black_masks = 0
        sample_masks = list(masks_path.glob("*.png"))[:min(10, len(list(masks_path.glob("*.png"))))]
        
        for mask_file in sample_masks:
            try:
                mask = np.array(Image.open(mask_file))
                if mask.max() == 0:
                    black_masks += 1
                else:
                    non_black_masks += 1
            except Exception as e:
                print(f"   ‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {mask_file.name}: {e}")
        
        total_checked = black_masks + non_black_masks
        if total_checked > 0:
            print(f"   –ü—Ä–æ–≤–µ—Ä–µ–Ω–æ –º–∞—Å–æ–∫: {total_checked}")
            print(f"   –ß—ë—Ä–Ω—ã—Ö (–ø—É—Å—Ç—ã—Ö): {black_masks}")
            print(f"   –° –¥–∞–Ω–Ω—ã–º–∏: {non_black_masks}")
            if black_masks > 0:
                print(f"   ‚ö†Ô∏è –ü–†–û–ë–õ–ï–ú–ê: –ú–∞—Å–∫–∏ –ø–æ–ª–Ω–æ—Å—Ç—å—é —á—ë—Ä–Ω—ã–µ!")
    
    # === 10. –í—ã—è–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º ===
    print(f"\n" + "=" * 60)
    print("üîç –í–´–Ø–í–õ–ï–ù–ù–´–ï –ü–†–û–ë–õ–ï–ú–´:")
    print("=" * 60)
    
    problems = []
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    if images:
        w, h = images[0]['width'], images[0]['height']
        if w < 1024 or h < 1024:
            problems.append(f"‚ö†Ô∏è –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π {w}x{h} < 1024x1024 (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    if len(images) < 1000:
        problems.append(f"‚ö†Ô∏è –¢–æ–ª—å–∫–æ {len(images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 1000+)")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∞–ª–µ–Ω—å–∫–∏—Ö bbox
    tiny_bboxes = sum(1 for a in bbox_areas if a < 10)
    if tiny_bboxes > 0:
        problems.append(f"‚ö†Ô∏è {tiny_bboxes} –æ—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–∏—Ö bbox (area < 10 –ø–∏–∫—Å–µ–ª–µ–π)")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏—Ä–æ—Ç
    if orphaned > 0:
        problems.append(f"‚ö†Ô∏è {orphaned} –ø–∞—Ä–∞–ª–ª–µ–ª–µ–ø–∏–ø–µ–¥–æ–≤ –±–µ–∑ –≤–∞–ª–∏–¥–Ω–æ–≥–æ parent_id")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —á—ë—Ä–Ω—ã—Ö –º–∞—Å–æ–∫
    if masks_path.exists() and black_masks > 0:
        problems.append(f"‚ùå {black_masks}/{total_checked} –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã—Ö –º–∞—Å–æ–∫ –ø–æ–ª–Ω–æ—Å—Ç—å—é —á—ë—Ä–Ω—ã–µ!")
    
    if problems:
        for p in problems:
            print(f"   {p}")
    else:
        print("   ‚úÖ –ü—Ä–æ–±–ª–µ–º –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ!")
    
    print("\n" + "=" * 60)

def main():
    if len(sys.argv) > 1:
        dataset_path = sys.argv[1]
    else:
        # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—â–µ–º –≤ —Ç–µ–∫—É—â–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        if os.path.exists("dataset"):
            dataset_path = "dataset"
        elif os.path.exists("strawberry_peduncle_segmentation/dataset"):
            dataset_path = "strawberry_peduncle_segmentation/dataset"
        else:
            dataset_path = "."
    
    analyze_dataset(dataset_path)

if __name__ == "__main__":
    main()
