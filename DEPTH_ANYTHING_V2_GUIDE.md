# üìè Depth Anything V2 + Unity Integration

## ‚úÖ –û—Ç–≤–µ—Ç: –î–ê, –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–∞–º–µ—Ä—ã –∏–∑ Unity!

### –ß—Ç–æ —Ç–∞–∫–æ–µ Depth Anything V2?

**Depth Anything V2** - —ç—Ç–æ state-of-the-art –º–æ–¥–µ–ª—å –¥–ª—è **monocular depth estimation** (–æ—Ü–µ–Ω–∫–∞ –≥–ª—É–±–∏–Ω—ã –ø–æ –æ–¥–Ω–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é).

**–í–µ—Ä—Å–∏–∏:**
- **V1** (2024): –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å, –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞
- **V2** (NeurIPS 2024): –£–ª—É—á—à–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å, **metric depth** (–≥–ª—É–±–∏–Ω–∞ –≤ –º–µ—Ç—Ä–∞—Ö)
- **V3**: –ü–æ–∫–∞ –Ω–µ –≤—ã–ø—É—â–µ–Ω–∞

### –ö–ª—é—á–µ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ V2:

1. **Metric Depth Estimation** - –≥–ª—É–±–∏–Ω–∞ –≤ –º–µ—Ç—Ä–∞—Ö (–Ω–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–∞—è!)
2. **–î–≤–∞ —Ä–µ–∂–∏–º–∞**:
   - Indoor (Hypersim): –¥–æ 20 –º–µ—Ç—Ä–æ–≤
   - Outdoor (Virtual KITTI): –¥–æ 80 –º–µ—Ç—Ä–æ–≤
3. **–ò—Å–ø–æ–ª—å–∑—É–µ—Ç camera intrinsics** –¥–ª—è —Ç–æ—á–Ω—ã—Ö –∏–∑–º–µ—Ä–µ–Ω–∏–π
4. **–ë—ã—Å—Ç—Ä–∞—è**: 10x –±—ã—Å—Ç—Ä–µ–µ —á–µ–º Stable Diffusion –º–æ–¥–µ–ª–∏

---

## üé• Unity Camera ‚Üí Depth Anything V2

### –ù–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ Unity:

```csharp
// Unity Camera
Camera camera = Camera.main;
float fov = camera.fieldOfView;  // –í–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–π FOV –≤ –≥—Ä–∞–¥—É—Å–∞—Ö
int width = 1024;
int height = 1024;
```

### –í—ã—á–∏—Å–ª–µ–Ω–∏–µ Focal Length:

```python
import math

# Unity –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
fov_vertical = 60.0  # –≥—Ä–∞–¥—É—Å—ã
image_height = 1024
image_width = 1024

# –§–æ—Ä–º—É–ª–∞
fov_rad = fov_vertical * math.pi / 180.0
focal_length_y = (image_height / 2.0) / math.tan(fov_rad / 2.0)
focal_length_x = focal_length_y  # –ï—Å–ª–∏ aspect ratio = 1:1

# –†–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è FOV=60¬∞, 1024x1024:
# focal_length = 886.4 –ø–∏–∫—Å–µ–ª–µ–π
```

### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ Depth Anything V2:

```python
from depth_anything_v2.dpt import DepthAnythingV2

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
model = DepthAnythingV2(
    encoder='vitl',
    features=256,
    out_channels=[256, 512, 1024, 1024],
    max_depth=20.0  # 20m –¥–ª—è indoor
)
model.load_state_dict(torch.load('depth_anything_v2_metric_hypersim_vitl.pth'))

# Inference
image_bgr = cv2.imread('unity_screenshot.png')
depth_map = model.infer_image(image_bgr)  # HxW array –≤ –ú–ï–¢–†–ê–•!

# depth_map[y, x] = —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –≤ –º–µ—Ç—Ä–∞—Ö –¥–æ –ø–∏–∫—Å–µ–ª—è (x, y)
```

---

## üìä –ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç Metric Depth

### 1. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏:

Depth Anything V2 Metric –æ–±—É—á–µ–Ω–∞ –Ω–∞:
- **Hypersim** (indoor): 77K —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å ground truth depth
- **Virtual KITTI** (outdoor): 21K —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π

–≠—Ç–∏ –¥–∞—Ç–∞—Å–µ—Ç—ã —Å–æ–¥–µ—Ä–∂–∞—Ç **—Ç–æ—á–Ω—ã–µ depth maps** —Å –∏–∑–≤–µ—Å—Ç–Ω—ã–º–∏ camera intrinsics.

### 2. Inference:

```python
# –ú–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç depth –≤ –º–µ—Ç—Ä–∞—Ö –Ω–∞–ø—Ä—è–º—É—é
depth = model.infer_image(image)

# –ú–æ–∂–Ω–æ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ point cloud
x, y = np.meshgrid(np.arange(width), np.arange(height))

# –ò—Å–ø–æ–ª—å–∑—É–µ–º focal length –∏–∑ Unity
x_3d = (x - width / 2) / focal_length_x * depth
y_3d = (y - height / 2) / focal_length_y * depth
z_3d = depth

points_3d = np.stack([x_3d, y_3d, z_3d], axis=-1)
```

### 3. –¢–æ—á–Ω–æ—Å—Ç—å:

| –î–∞—Ç–∞—Å–µ—Ç | AbsRel ‚Üì | RMSE ‚Üì | Œ¥1 ‚Üë |
|---------|----------|--------|------|
| Hypersim | 0.058 | 0.141 | 0.981 |
| Virtual KITTI | 0.048 | 0.387 | 0.992 |

- **AbsRel**: –°—Ä–µ–¥–Ω—è—è –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–∞—è –æ—à–∏–±–∫–∞ (—á–µ–º –º–µ–Ω—å—à–µ, —Ç–µ–º –ª—É—á—à–µ)
- **RMSE**: Root Mean Square Error
- **Œ¥1**: % –ø–∏–∫—Å–µ–ª–µ–π —Å –æ—à–∏–±–∫–æ–π < 25% (—á–µ–º –±–æ–ª—å—à–µ, —Ç–µ–º –ª—É—á—à–µ)

---

## üîß –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Unity

### –í–∞—Ä–∏–∞–Ω—Ç 1: –≠–∫—Å–ø–æ—Ä—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∫–∞–º–µ—Ä—ã

```csharp
// Unity Script –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ camera intrinsics
using UnityEngine;
using System.IO;

public class CameraIntrinsicsExporter : MonoBehaviour
{
    public Camera targetCamera;
    
    [ContextMenu("Export Camera Intrinsics")]
    public void ExportIntrinsics()
    {
        float fov = targetCamera.fieldOfView;
        int width = targetCamera.pixelWidth;
        int height = targetCamera.pixelHeight;
        
        // –í—ã—á–∏—Å–ª–µ–Ω–∏–µ focal length
        float fovRad = fov * Mathf.Deg2Rad;
        float focalLengthY = (height / 2.0f) / Mathf.Tan(fovRad / 2.0f);
        float focalLengthX = focalLengthY; // Square aspect
        
        // –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ JSON
        var intrinsics = new
        {
            fov_vertical = fov,
            width = width,
            height = height,
            focal_length_x = focalLengthX,
            focal_length_y = focalLengthY,
            principal_point_x = width / 2.0f,
            principal_point_y = height / 2.0f
        };
        
        string json = JsonUtility.ToJson(intrinsics, true);
        File.WriteAllText("camera_intrinsics.json", json);
        
        Debug.Log($"Camera intrinsics exported: focal_length={focalLengthX:F2}px");
    }
}
```

### –í–∞—Ä–∏–∞–Ω—Ç 2: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–∏ –∑–∞—Ö–≤–∞—Ç–µ

–î–æ–±–∞–≤–∏—Ç—å –≤ `BatchDatasetCapture.cs`:

```csharp
private void SaveCameraIntrinsics(string basePath)
{
    var intrinsics = new
    {
        fov_vertical = mainCamera.fieldOfView,
        width = imageWidth,
        height = imageHeight,
        focal_length_x = CalculateFocalLength(),
        focal_length_y = CalculateFocalLength()
    };
    
    string json = JsonUtility.ToJson(intrinsics, true);
    File.WriteAllText(Path.Combine(basePath, "camera_intrinsics.json"), json);
}

private float CalculateFocalLength()
{
    float fovRad = mainCamera.fieldOfView * Mathf.Deg2Rad;
    return (imageHeight / 2.0f) / Mathf.Tan(fovRad / 2.0f);
}
```

---

## üöÄ –ü–æ–ª–Ω—ã–π Pipeline

### 1. Unity ‚Üí –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞

```
Unity BatchDatasetCapture
    ‚Üì
–ì–µ–Ω–µ—Ä–∞—Ü–∏—è 1000 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    ‚Üì
–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ:
  - images/*.png
  - masks/*.png
  - annotations.json
  - camera_intrinsics.json  ‚Üê –ù–û–í–û–ï!
```

### 2. Python ‚Üí –û–±—É—á–µ–Ω–∏–µ Segmentation

```python
# train_segmentation.ipynb
Mask R-CNN –æ–±—É—á–∞–µ—Ç—Å—è –Ω–∞:
  - Segmentation (–∫—É–±—ã, –ø–∞—Ä–∞–ª–ª–µ–ª–µ–ø–∏–ø–µ–¥—ã)
  - –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–≤—è–∑–µ–π
```

### 3. Python ‚Üí Depth Estimation + Inference

```python
# depth_estimation_inference.ipynb

# –ó–∞–≥—Ä—É–∑–∫–∞ camera intrinsics
with open('camera_intrinsics.json') as f:
    intrinsics = json.load(f)

focal_length = intrinsics['focal_length_x']

# Depth estimation
depth_map = depth_model.infer_image(image)

# Segmentation
segmentation = segmentation_model(image)

# –î–ª—è –∫–∞–∂–¥–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞:
for obj in segmentation:
    # –ò–∑–≤–ª–µ–∫–∞–µ–º depth –¥–ª—è –ø–∏–∫—Å–µ–ª–µ–π –æ–±—ä–µ–∫—Ç–∞
    object_depths = depth_map[obj['mask']]
    
    # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ
    distance = np.median(object_depths)
    
    print(f"{obj['category']}: {distance:.2f}m")
```

---

## üìà –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ —ç—Ç–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞

### ‚úÖ –ü–ª—é—Å—ã:

1. **–¢–æ—á–Ω—ã–µ –º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è** (–≤ –º–µ—Ç—Ä–∞—Ö, –Ω–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ)
2. **–ù–µ —Ç—Ä–µ–±—É–µ—Ç depth sensor** - —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –æ–±—ã—á–Ω–æ–π RGB –∫–∞–º–µ—Ä–æ–π
3. **–ë—ã—Å—Ç—Ä—ã–π inference** (~30 FPS –Ω–∞ GPU)
4. **–ü—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å** - –Ω–µ –Ω—É–∂–Ω–æ –æ–±—É—á–∞—Ç—å —Å –Ω—É–ª—è
5. **–°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å Unity** - –ª–µ–≥–∫–æ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å

### ‚ö†Ô∏è –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è:

1. **–¢–æ—á–Ω–æ—Å—Ç—å –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Å—Ü–µ–Ω—ã**:
   - –õ—É—á—à–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ indoor —Å—Ü–µ–Ω–∞—Ö (–∫–∞–∫ –Ω–∞—à –¥–∞—Ç–∞—Å–µ—Ç)
   - –•—É–∂–µ –Ω–∞ outdoor —Å –±–æ–ª—å—à–∏–º–∏ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è–º–∏
2. **–¢—Ä–µ–±—É–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö camera intrinsics**:
   - –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π focal length ‚Üí –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è
3. **Monocular depth** - –Ω–µ—Ç —Å—Ç–µ—Ä–µ–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏:
   - –ú–æ–∂–µ—Ç –æ—à–∏–±–∞—Ç—å—Å—è –Ω–∞ —Ç–µ–∫—Å—Ç—É—Ä–∞—Ö –±–µ–∑ –≥–ª—É–±–∏–Ω—ã
   - –ü—Ä–æ–±–ª–µ–º—ã —Å –ø—Ä–æ–∑—Ä–∞—á–Ω—ã–º–∏ –æ–±—ä–µ–∫—Ç–∞–º–∏

---

## üéØ –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –¥–ª—è –≤–∞—à–µ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞

### –ß—Ç–æ –≤—ã –ø–æ–ª—É—á–∞–µ—Ç–µ:

1. **Segmentation**: Mask R-CNN –Ω–∞—Ö–æ–¥–∏—Ç –∫—É–±—ã –∏ –ø–∞—Ä–∞–ª–ª–µ–ª–µ–ø–∏–ø–µ–¥—ã
2. **Associations**: –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–∞–∫–æ–π –ø–∞—Ä–∞–ª–ª–µ–ª–µ–ø–∏–ø–µ–¥ –Ω–∞ –∫–∞–∫–æ–º –∫—É–±–µ
3. **Depth**: Depth Anything V2 –¥–∞–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ –∫–∞–∂–¥–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞
4. **3D Position**: –ú–æ–∂–Ω–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å 3D –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã

### –ü—Ä–∏–º–µ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:

```json
{
  "image": "00042.png",
  "objects": [
    {
      "id": 0,
      "category": "red_cube",
      "bbox": [512, 600, 580, 668],
      "distance": {
        "center": 0.85,  // –º–µ—Ç—Ä—ã
        "mean": 0.87,
        "min": 0.82,
        "max": 0.91
      }
    },
    {
      "id": 1,
      "category": "green_parallelepiped",
      "bbox": [530, 550, 562, 600],
      "parent_id": 0,  // –ü—Ä–∏–Ω–∞–¥–ª–µ–∂–∏—Ç –∫—É–±—É #0
      "distance": {
        "center": 0.83,  // –ë–ª–∏–∂–µ —á–µ–º –∫—É–± (—Å–≤–µ—Ä—Ö—É)
        "mean": 0.84,
        "min": 0.81,
        "max": 0.86
      }
    }
  ]
}
```

---

## üìö –°—Å—ã–ª–∫–∏

- **Depth Anything V2 Paper**: https://arxiv.org/abs/2406.09414
- **GitHub**: https://github.com/DepthAnything/Depth-Anything-V2
- **Metric Depth**: https://github.com/DepthAnything/Depth-Anything-V2/tree/main/metric_depth
- **HuggingFace Demo**: https://huggingface.co/spaces/Depth-Anything/Depth-Anything-V2

---

## üöÄ Depth Anything V3 (–ù–û–í–ò–ù–ö–ê!)

**–°—Ç–∞—Ç—É—Å**: ‚úÖ **–í–´–ü–£–©–ï–ù–ê!** (—è–Ω–≤–∞—Ä—å 2026)

**GitHub**: https://github.com/ByteDance-Seed/Depth-Anything-3

### üéØ –ö–ª—é—á–µ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ V3:

**Depth Anything V3** - —ç—Ç–æ —Ä–µ–≤–æ–ª—é—Ü–∏–æ–Ω–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ, –∫–æ—Ç–æ—Ä–æ–µ **–ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç V2** –ø–æ –≤—Å–µ–º –º–µ—Ç—Ä–∏–∫–∞–º!

#### üì¶ –¢—Ä–∏ —Å–µ—Ä–∏–∏ –º–æ–¥–µ–ª–µ–π:

1. **DA3 Main Series** (Giant, Large, Base, Small):
   - üåä **Monocular Depth** - depth –∏–∑ –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
   - üåä **Multi-View Depth** - consistent depth –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
   - üéØ **Pose-Conditioned Depth** - depth —Å —É—á—ë—Ç–æ–º camera pose
   - üì∑ **Camera Pose Estimation** - –æ—Ü–µ–Ω–∫–∞ extrinsics –∏ intrinsics
   - üü° **3D Gaussian Estimation** - –ø—Ä—è–º–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ 3D Gaussians!

2. **DA3 Metric Series** (DA3Metric-Large):
   - –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è **metric depth –≤ –º–µ—Ç—Ä–∞—Ö**
   - –§–æ—Ä–º—É–ª–∞: `metric_depth = focal * net_output / 300.0`
   - –ò–¥–µ–∞–ª—å–Ω–æ –¥–ª—è –≤–∞—à–µ–≥–æ Unity –ø—Ä–æ–µ–∫—Ç–∞!

3. **DA3 Monocular Series** (DA3Mono-Large):
   - –í—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è relative depth
   - –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç depth –Ω–∞–ø—Ä—è–º—É—é (–Ω–µ disparity –∫–∞–∫ V2)

#### üåü DA3 Nested Series:

**DA3NESTED-GIANT-LARGE-1.1** - –∫–æ–º–±–∏–Ω–∞—Ü–∏—è any-view –º–æ–¥–µ–ª–∏ + metric –º–æ–¥–µ–ª–∏:
- ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç camera pose
- ‚úÖ –í—ã–¥–∞—ë—Ç depth **—Å—Ä–∞–∑—É –≤ –º–µ—Ç—Ä–∞—Ö** (–Ω–µ –Ω—É–∂–Ω–∞ —Ñ–æ—Ä–º—É–ª–∞!)
- ‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç —Å –æ–¥–Ω–∏–º –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
- ‚úÖ –õ—É—á—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞ street scenes

### üÜö V3 vs V2: –ß—Ç–æ –ª—É—á—à–µ?

| –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å | V2 | V3 |
|-------------|----|----|
| Monocular Depth | ‚úÖ | ‚úÖ –õ—É—á—à–µ |
| Metric Depth | ‚úÖ | ‚úÖ –õ—É—á—à–µ |
| Multi-View Depth | ‚ùå | ‚úÖ **–ù–û–í–û–ï!** |
| Camera Pose Estimation | ‚ùå | ‚úÖ **–ù–û–í–û–ï!** |
| 3D Gaussians | ‚ùå | ‚úÖ **–ù–û–í–û–ï!** |
| –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ | DINOv2 + DPT | Plain Transformer |
| –¢–æ—á–Ω–æ—Å—Ç—å | –•–æ—Ä–æ—à–∞—è | **–õ—É—á—à–∞—è** |

### üí° –î–ª—è –≤–∞—à–µ–≥–æ Unity –ø—Ä–æ–µ–∫—Ç–∞:

**–†–µ–∫–æ–º–µ–Ω–¥—É—é –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å V3!** –í–æ—Ç –ø–æ—á–µ–º—É:

#### –í–∞—Ä–∏–∞–Ω—Ç 1: DA3METRIC-LARGE (–ø—Ä–æ—Å—Ç–æ–π)
```python
from depth_anything_3.api import DepthAnything3

model = DepthAnything3.from_pretrained("depth-anything/DA3METRIC-LARGE")
model = model.to("cuda")

prediction = model.inference([image])

# –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ –º–µ—Ç—Ä—ã —Å Unity focal length
focal_length = 886.4  # –∏–∑ Unity FOV=60¬∞
metric_depth = focal_length * prediction.depth / 300.0

# metric_depth —Ç–µ–ø–µ—Ä—å –≤ –º–µ—Ç—Ä–∞—Ö!
```

#### –í–∞—Ä–∏–∞–Ω—Ç 2: DA3NESTED-GIANT-LARGE-1.1 (–ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π)
```python
model = DepthAnything3.from_pretrained("depth-anything/DA3NESTED-GIANT-LARGE-1.1")
model = model.to("cuda")

prediction = model.inference([image])

# prediction.depth –£–ñ–ï –≤ –º–µ—Ç—Ä–∞—Ö!
# prediction.intrinsics - –æ—Ü–µ–Ω—ë–Ω–Ω—ã–µ camera intrinsics
# prediction.extrinsics - camera pose (–µ—Å–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π)

print(f"Depth range: {prediction.depth.min():.2f}m - {prediction.depth.max():.2f}m")
print(f"Estimated focal length: {prediction.intrinsics[0, 0, 0]:.2f}px")
```

### üéÅ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ V3:

1. **–≠–∫—Å–ø–æ—Ä—Ç –≤ —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã**:
   - `.glb` - 3D –º–æ–¥–µ–ª–∏
   - `.ply` - point clouds
   - `.npz` - numpy arrays
   - 3D Gaussian Splatting videos

2. **Web UI** - Gradio –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏

3. **CLI** - –º–æ—â–Ω—ã–π command-line interface:
```bash
da3 auto assets/examples/SOH \
  --export-format glb \
  --export-dir output/
```

### üìä –¢–æ—á–Ω–æ—Å—Ç—å V3:

**AUC3 –º–µ—Ç—Ä–∏–∫–∞** (—á–µ–º –≤—ã—à–µ, —Ç–µ–º –ª—É—á—à–µ):

| Dataset | V2 | V3 (Nested) |
|---------|-------|-------------|
| HiRoom | - | **84.4** |
| ETH3D | - | **52.6** |
| DTU | - | **93.9** |
| ScanNet++ | - | **89.4** |

### ‚ö†Ô∏è –í–∞–∂–Ω—ã–µ –¥–µ—Ç–∞–ª–∏:

1. **–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–æ–¥–µ–ª–∏ —Å —Å—É—Ñ—Ñ–∏–∫—Å–æ–º `-1.1`** - –æ–Ω–∏ –∏—Å–ø—Ä–∞–≤–ª—è—é—Ç –±–∞–≥ –æ–±—É—á–µ–Ω–∏—è
2. **`use_ray_pose=True`** - –º–µ–¥–ª–µ–Ω–Ω–µ–µ, –Ω–æ —Ç–æ—á–Ω–µ–µ –¥–ª—è camera pose
3. **Nested –º–æ–¥–µ–ª–∏** –≤—ã–¥–∞—é—Ç depth —Å—Ä–∞–∑—É –≤ –º–µ—Ç—Ä–∞—Ö (–Ω–µ –Ω—É–∂–Ω–∞ —Ñ–æ—Ä–º—É–ª–∞)

### üîß –£—Å—Ç–∞–Ω–æ–≤–∫–∞ V3:

```bash
pip install xformers torch>=2 torchvision
pip install git+https://github.com/ByteDance-Seed/Depth-Anything-3.git
```

---

## üéØ –ò—Ç–æ–≥–æ–≤–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –¥–ª—è Unity –ø—Ä–æ–µ–∫—Ç–∞:

### –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ **Depth Anything V3 (DA3NESTED-GIANT-LARGE-1.1)**!

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞**:
- ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç camera intrinsics (–Ω–µ –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å –∏–∑ Unity!)
- ‚úÖ Depth —Å—Ä–∞–∑—É –≤ –º–µ—Ç—Ä–∞—Ö
- ‚úÖ –õ—É—á—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å
- ‚úÖ –ú–æ–∂–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ –¥–ª—è –ª—É—á—à–µ–π consistency
- ‚úÖ –û—Ü–µ–Ω–∏–≤–∞–µ—Ç camera pose (–ø–æ–ª–µ–∑–Ω–æ –¥–ª—è multi-view)

**–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞**: –ï—Å–ª–∏ –Ω—É–∂–Ω–∞ —Å–∫–æ—Ä–æ—Å—Ç—å, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ **DA3METRIC-LARGE** (–±—ã—Å—Ç—Ä–µ–µ, –Ω–æ –Ω—É–∂–µ–Ω focal length –∏–∑ Unity)
